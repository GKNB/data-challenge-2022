{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becd5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a286685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 23:11:07.365324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.370469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.371625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.373181: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-13 23:11:07.374978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.376122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.377246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.708804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.709965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.711078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:07.712169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /device:GPU:0 with 46625 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0047e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.layers import Input, Lambda, LeakyReLU, Add, Dense, Activation, Flatten, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import glorot_uniform, constant, TruncatedNormal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb9ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('processed_data/np_gan_standard.h5', 'r') as hf:\n",
    "    data_lr = hf['np_lr'][:]\n",
    "    data_lr_mean = hf['np_lr_mean'][:]\n",
    "    data_lr_stddev = hf['np_lr_stddev'][:]\n",
    "    data_hr = hf['np_hr'][:]\n",
    "    data_hr_mean = hf['np_hr_mean'][:]\n",
    "    data_hr_stddev = hf['np_hr_stddev'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7475c3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8520, 96, 96, 2)\n",
      "[ 0.7051484 -1.0147774]\n",
      "[3.1869051 2.8827915]\n",
      "\n",
      "\n",
      "(8520, 192, 192, 2)\n",
      "[ 0.701198  -1.0068085]\n",
      "[3.149407  2.8781955]\n"
     ]
    }
   ],
   "source": [
    "print(data_lr.shape)\n",
    "print(data_lr_mean)\n",
    "print(data_lr_stddev)\n",
    "print('\\n')\n",
    "print(data_hr.shape)\n",
    "print(data_hr_mean)\n",
    "print(data_hr_stddev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956f9245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5112, 96, 96, 2)\n",
      "(1704, 96, 96, 2)\n",
      "(1704, 96, 96, 2)\n",
      "(5112, 192, 192, 2)\n",
      "(1704, 192, 192, 2)\n",
      "(1704, 192, 192, 2)\n",
      "6.890482 5.989441 5.7024393 -5.4777956 -5.0524907 -5.5057893\n",
      "7.035497 5.8600492 6.0442076 -5.315754 -5.2317853 -5.2996855\n"
     ]
    }
   ],
   "source": [
    "#First split data into train+validation and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_lr, data_hr, test_size=0.2, random_state=42)\n",
    "\n",
    "#Next split training again into train and validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(np.max(x_train), np.max(x_val), np.max(x_test), np.min(x_train), np.min(x_val), np.min(x_test))\n",
    "print(np.max(y_train), np.max(y_val), np.max(y_test), np.min(y_train), np.min(y_val), np.min(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cac26099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_shape = (96, 96, 2), nf = 64, r = 2):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset, H*W*C\n",
    "    nf -- integer, the number of filters in all convT layer before super-resolution step\n",
    "    r -- integer, resolution ratio between output and input\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    C0 = input_shape[2]\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Define kernel size and stride used\n",
    "    k, stride = 3, 1\n",
    "    \n",
    "    # Shall we use a mirror padding and finally cutoff the edge, like the paper does? FIXME\n",
    "    X = Conv2DTranspose(filters=nf, kernel_size=(k, k), strides=(stride, stride), padding='same')(X_input)\n",
    "    # Shall we use relu, or leaky_relu? FIXME\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    skip_connection = X\n",
    "    \n",
    "    for i in range(16):\n",
    "        X_shortcut = X\n",
    "        \n",
    "        X = Conv2DTranspose(filters=nf, kernel_size=(k, k), strides=(stride, stride), padding='same')(X)\n",
    "        X = Activation('relu')(X)\n",
    "        X = Conv2DTranspose(filters=nf, kernel_size=(k, k), strides=(stride, stride), padding='same')(X)\n",
    "        X = Add()([X, X_shortcut])\n",
    "        # Are we missing a relu activation here, if we follow the resnet paper? FIXME\n",
    "    \n",
    "    X = Conv2DTranspose(filters=nf, kernel_size=(k, k), strides=(stride, stride), padding='same')(X)\n",
    "    X = Add()([X, skip_connection])\n",
    "    \n",
    "    # Start to perform sr\n",
    "    nf_sr = (r**2) * nf\n",
    "    X = Conv2DTranspose(filters=nf_sr, kernel_size=(k, k), strides=(stride, stride), padding='same')(X)\n",
    "    \n",
    "    sub_layer = Lambda(lambda x:tf.nn.depth_to_space(x,r))\n",
    "    X = sub_layer(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2DTranspose(filters=C0, kernel_size=(k, k), strides=(stride, stride), padding='same')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833b352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 23:11:09.868396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:09.869588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:09.870679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:09.871793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:09.872868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-13 23:11:09.873935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46625 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 96, 96, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 96, 96, 64)  1216        ['input_1[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 96, 96, 64)   0           ['conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation[0][0]']             \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_1[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 96, 96, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 96, 96, 64)  36928       ['add[0][0]']                    \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_2[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 96, 96, 64)  36928       ['add_1[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_3[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_6[0][0]',     \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 96, 96, 64)  36928       ['add_2[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_4[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_8[0][0]',     \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 96, 96, 64)  36928       ['add_3[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_5[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_10[0][0]',    \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_4[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_6[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_12[0][0]',    \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_13 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_5[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_13[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_14 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_7[0][0]']           \n",
      " nspose)                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_14[0][0]',    \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_15 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_6[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_15[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_16 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_8[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_16[0][0]',    \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_17 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_7[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_17[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_18 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_9[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_18[0][0]',    \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_19 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_8[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_19[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_20 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_10[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_20[0][0]',    \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_21 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_9[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_21[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_22 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_11[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_22[0][0]',    \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_23 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_10[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_23[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_24 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_12[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_24[0][0]',    \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_25 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_11[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_25[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_26 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_13[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_26[0][0]',    \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_27 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_12[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_27[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_28 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_14[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_28[0][0]',    \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_29 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_13[0][0]']                 \n",
      " nspose)                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_29[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_30 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_15[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_30[0][0]',    \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_31 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_14[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_31[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_32 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_16[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_32[0][0]',    \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_33 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_15[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_33[0][0]',    \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_34 (Conv2DTra  (None, 96, 96, 256)  147712     ['add_16[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 192, 192, 64  0           ['conv2d_transpose_34[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 192, 192, 64  0           ['lambda[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_35 (Conv2DTra  (None, 192, 192, 2)  1154       ['activation_17[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,368,706\n",
      "Trainable params: 1,368,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gen_model = generator(input_shape = (96, 96, 2))\n",
    "print(gen_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8256dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape = (192, 192, 2)):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset, H*W*C\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    C0 = input_shape[2]\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #conv1\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\")(X_input)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #conv2\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), padding=\"same\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #conv3\n",
    "    X = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding=\"same\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #conv4\n",
    "    X = Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), padding=\"same\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #conv5\n",
    "    X = Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"same\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #conv6\n",
    "    X = Conv2D(filters=128, kernel_size=(3,3), strides=(2,2), padding=\"same\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #conv7\n",
    "    X = Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding=\"same\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #conv8\n",
    "    X = Conv2D(filters=256, kernel_size=(3,3), strides=(2,2), padding=\"same\")(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    \n",
    "    #first fully-connect\n",
    "    k_init = TruncatedNormal(stddev=0.02)\n",
    "    X = Dense(units=1024, kernel_initializer=k_init)(X)\n",
    "    X = LeakyReLU(alpha=0.2)(X)\n",
    "    \n",
    "    #second fully-connect, no activation FIXME\n",
    "    X = Dense(units=1, kernel_initializer=k_init)(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d036ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 192, 192, 2)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 192, 192, 32)      608       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 192, 192, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 96, 96, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 48, 48, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 48, 48, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 24, 24, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              37749760  \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,922,753\n",
      "Trainable params: 38,922,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "disc_model = discriminator(input_shape = (192, 192, 2))\n",
    "print(disc_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbcf4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(x_HR, x_SR, d_HR, d_SR, alpha_advers=0.001, isGAN=False):\n",
    "\n",
    "    content_loss = tf.reduce_mean((x_HR - x_SR)**2, axis=[1, 2, 3])\n",
    "\n",
    "    if isGAN:\n",
    "        g_advers_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=d_SR, labels=tf.ones_like(d_SR))\n",
    "\n",
    "        d_advers_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.concat([d_HR, d_SR], axis=0),\n",
    "                                                                labels=tf.concat([tf.ones_like(d_HR), tf.zeros_like(d_SR)], axis=0))\n",
    "\n",
    "        advers_perf = [tf.reduce_mean(tf.cast(tf.sigmoid(d_HR) > 0.5, tf.float32)), # % true positive\n",
    "                       tf.reduce_mean(tf.cast(tf.sigmoid(d_SR) < 0.5, tf.float32)), # % true negative\n",
    "                       tf.reduce_mean(tf.cast(tf.sigmoid(d_SR) > 0.5, tf.float32)), # % false positive\n",
    "                       tf.reduce_mean(tf.cast(tf.sigmoid(d_HR) < 0.5, tf.float32))] # % false negative\n",
    "\n",
    "        g_loss = tf.reduce_mean(content_loss) + alpha_advers*tf.reduce_mean(g_advers_loss)\n",
    "        d_loss = tf.reduce_mean(d_advers_loss)\n",
    "\n",
    "        return g_loss, d_loss, advers_perf, tf.reduce_mean(content_loss), tf.reduce_mean(g_advers_loss)\n",
    "    else:\n",
    "        return tf.reduce_mean(content_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65fea1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2cc00f7b20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.load_weights(\"gan_v1/ckp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "949088a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 23:11:22.121148: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 5s 51ms/step\n",
      "tf.Tensor(0.011780102, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(compute_losses(y_test, gen_model.predict(x_test), None, None, 0.001, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f255dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 3s 52ms/step - loss: 0.0118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01178010180592537"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "gen_model.compile(optimizer=adam, loss=losses.MeanSquaredError())\n",
    "\n",
    "gen_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682d2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "def pretrain(epochs=20, batch_size=128):\n",
    "    '''\n",
    "        This method trains the generator without using a disctiminator/adversarial training. \n",
    "        output:  generator model\n",
    "    '''\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "    batch_count = tf.data.experimental.cardinality(train_dataset)\n",
    "     \n",
    "    gen_model = generator(input_shape = (96, 96, 2)) \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    # Start training\n",
    "    print('Training network ...')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print('Epoch: %d' %(epoch))\n",
    "        start_time = time()\n",
    "        epoch_loss, N = 0, 0\n",
    "        \n",
    "        for batch_idx, (batch_LR, batch_HR) in enumerate(train_dataset):\n",
    "            N_batch = batch_LR.shape[0]\n",
    "            \n",
    "            with tf.GradientTape() as gen_tape:\n",
    "                batch_SR = gen_model(batch_LR, training=True)\n",
    "                gen_loss = compute_losses(batch_HR, batch_SR, None, None, alpha_advers=0.001, isGAN=False)\n",
    "            \n",
    "            grad_of_gen = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n",
    "            adam.apply_gradients(zip(grad_of_gen, gen_model.trainable_variables))\n",
    "\n",
    "            epoch_loss += gen_loss * N_batch\n",
    "            N += N_batch\n",
    "\n",
    "        epoch_loss = epoch_loss / N       \n",
    "        \n",
    "        val_SR = gen_model.predict(x_val, verbose=0)\n",
    "        gen_val_loss = compute_losses(y_val, val_SR, None, None, alpha_advers=0.001, isGAN=False)\n",
    "        \n",
    "        print('Epoch generator training loss = %.6f, val loss = %6f' %(epoch_loss, gen_val_loss))\n",
    "        print('Epoch took %.2f seconds\\n' %(time() - start_time), flush=True)\n",
    "        train_loss.append(epoch_loss)\n",
    "        val_loss.append(gen_val_loss)\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "    return gen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef2b9ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Epoch: 1\n",
      "Epoch generator training loss = 0.550237, val loss = 0.098597\n",
      "Epoch took 40.95 seconds\n",
      "\n",
      "Epoch: 2\n",
      "Epoch generator training loss = 0.078973, val loss = 0.066691\n",
      "Epoch took 36.89 seconds\n",
      "\n",
      "Epoch: 3\n",
      "Epoch generator training loss = 0.058697, val loss = 0.052967\n",
      "Epoch took 36.83 seconds\n",
      "\n",
      "Epoch: 4\n",
      "Epoch generator training loss = 0.048061, val loss = 0.044717\n",
      "Epoch took 36.59 seconds\n",
      "\n",
      "Epoch: 5\n",
      "Epoch generator training loss = 0.041491, val loss = 0.039424\n",
      "Epoch took 36.50 seconds\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "gen_model3 = pretrain(5, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63076397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 3s 52ms/step - loss: 0.0407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.040661320090293884"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model3.compile(optimizer=adam, loss=losses.MeanSquaredError())\n",
    "gen_model3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e176fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def train(gen_model, disc_model, epochs=20, batch_size=128, alpha_advers=0.001):\n",
    "    '''\n",
    "        This method trains the generator and disctiminator adversarially\n",
    "        Notice the two model should be argument of this function\n",
    "        output: generator model and discriminator model\n",
    "    '''\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "    batch_count = tf.data.experimental.cardinality(train_dataset)\n",
    "    \n",
    "    adam_slow = tf.keras.optimizers.Adam(learning_rate=2e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    adam_fast = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    # Start training\n",
    "    print('Training network ...')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print('Epoch: %d' %(epoch))\n",
    "        start_time = time()\n",
    "        epoch_g_loss, epoch_d_loss, N = 0, 0, 0\n",
    "        \n",
    "        for batch_idx, (batch_LR, batch_HR) in enumerate(train_dataset):\n",
    "            N_batch = batch_LR.shape[0]\n",
    "            \n",
    "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                batch_SR = gen_model(batch_LR, training=True)\n",
    "                d_HR = disc_model(batch_HR, training=True)\n",
    "                d_SR = disc_model(batch_SR, training=True)\n",
    "                g_loss, d_loss, advers_perf, content_loss, g_advers_loss \\\n",
    "                        = compute_losses(batch_HR, batch_SR, d_HR, d_SR, alpha_advers=0.001, isGAN=True)\n",
    "            \n",
    "            grad_of_gen = gen_tape.gradient(g_loss, gen_model.trainable_variables)\n",
    "            adam_fast.apply_gradients(zip(grad_of_gen, gen_model.trainable_variables))\n",
    "            \n",
    "            grad_of_disc = disc_tape.gradient(d_loss, disc_model.trainable_variables)\n",
    "            adam_slow.apply_gradients(zip(grad_of_disc, disc_model.trainable_variables))\n",
    "\n",
    "            epoch_g_loss += g_loss * N_batch\n",
    "            epoch_d_loss += d_loss * N_batch\n",
    "            N += N_batch\n",
    "\n",
    "\n",
    "        epoch_g_loss = epoch_g_loss / N       \n",
    "        epoch_d_loss = epoch_d_loss / N       \n",
    "        \n",
    "        val_SR = gen_model.predict(x_val, verbose=0)\n",
    "        val_d_HR = disc_model.predict(y_val, verbose=0)\n",
    "        val_d_SR = disc_model.predict(val_SR, verbose=0)\n",
    "        val_g_loss, val_d_loss, val_advers_perf, val_content_loss, val_g_advers_loss \\\n",
    "                    = compute_losses(y_val, val_SR, val_d_HR, val_d_SR, alpha_advers=0.001, isGAN=True)\n",
    "\n",
    "        print('Epoch generator loss = %.6f, discriminator loss = %.6f' %(epoch_g_loss, epoch_d_loss))\n",
    "        print('Epoch val: g_loss = %.6f, d_loss = %.6f, content_loss = %.6f, advers_loss = %.6f' \\\n",
    "              %(val_g_loss, val_d_loss, val_content_loss, val_g_advers_loss))\n",
    "        print('Epoch took %.2f seconds\\n' %(time() - start_time), flush=True)\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "    return gen_model, disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd28c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Epoch: 1\n",
      "Epoch generator loss = 0.013467, discriminator loss = 0.550541\n",
      "Epoch val: g_loss = 0.013649, d_loss = 0.457951, content_loss = 0.012198, advers_loss = 1.451408\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 2\n",
      "Epoch generator loss = 0.011170, discriminator loss = 0.392340\n",
      "Epoch val: g_loss = 0.013552, d_loss = 0.312669, content_loss = 0.012297, advers_loss = 1.254653\n",
      "Epoch took 71.60 seconds\n",
      "\n",
      "Epoch: 3\n",
      "Epoch generator loss = 0.011610, discriminator loss = 0.248692\n",
      "Epoch val: g_loss = 0.014092, d_loss = 0.238705, content_loss = 0.012744, advers_loss = 1.347879\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 4\n",
      "Epoch generator loss = 0.012828, discriminator loss = 0.195272\n",
      "Epoch val: g_loss = 0.015999, d_loss = 0.171700, content_loss = 0.013317, advers_loss = 2.681944\n",
      "Epoch took 71.15 seconds\n",
      "\n",
      "Epoch: 5\n",
      "Epoch generator loss = 0.013769, discriminator loss = 0.190774\n",
      "Epoch val: g_loss = 0.017635, d_loss = 0.212673, content_loss = 0.014325, advers_loss = 3.310584\n",
      "Epoch took 71.14 seconds\n",
      "\n",
      "Epoch: 6\n",
      "Epoch generator loss = 0.014484, discriminator loss = 0.201424\n",
      "Epoch val: g_loss = 0.017384, d_loss = 0.226248, content_loss = 0.014313, advers_loss = 3.071452\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 7\n",
      "Epoch generator loss = 0.015025, discriminator loss = 0.212050\n",
      "Epoch val: g_loss = 0.017187, d_loss = 0.201971, content_loss = 0.014733, advers_loss = 2.453314\n",
      "Epoch took 71.29 seconds\n",
      "\n",
      "Epoch: 8\n",
      "Epoch generator loss = 0.015218, discriminator loss = 0.227459\n",
      "Epoch val: g_loss = 0.017221, d_loss = 0.218854, content_loss = 0.014870, advers_loss = 2.351304\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 9\n",
      "Epoch generator loss = 0.015453, discriminator loss = 0.216076\n",
      "Epoch val: g_loss = 0.017246, d_loss = 0.187111, content_loss = 0.014858, advers_loss = 2.388031\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 10\n",
      "Epoch generator loss = 0.015680, discriminator loss = 0.202455\n",
      "Epoch val: g_loss = 0.017487, d_loss = 0.186434, content_loss = 0.014880, advers_loss = 2.606613\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 11\n",
      "Epoch generator loss = 0.015562, discriminator loss = 0.218239\n",
      "Epoch val: g_loss = 0.017476, d_loss = 0.173533, content_loss = 0.014715, advers_loss = 2.760942\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 12\n",
      "Epoch generator loss = 0.015529, discriminator loss = 0.222628\n",
      "Epoch val: g_loss = 0.016591, d_loss = 0.193247, content_loss = 0.014548, advers_loss = 2.042139\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 13\n",
      "Epoch generator loss = 0.015514, discriminator loss = 0.215746\n",
      "Epoch val: g_loss = 0.017178, d_loss = 0.177814, content_loss = 0.014517, advers_loss = 2.660842\n",
      "Epoch took 71.29 seconds\n",
      "\n",
      "Epoch: 14\n",
      "Epoch generator loss = 0.015483, discriminator loss = 0.206213\n",
      "Epoch val: g_loss = 0.016512, d_loss = 0.199478, content_loss = 0.014439, advers_loss = 2.073602\n",
      "Epoch took 71.31 seconds\n",
      "\n",
      "Epoch: 15\n",
      "Epoch generator loss = 0.015517, discriminator loss = 0.196685\n",
      "Epoch val: g_loss = 0.017714, d_loss = 0.203732, content_loss = 0.014496, advers_loss = 3.217649\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 16\n",
      "Epoch generator loss = 0.015366, discriminator loss = 0.223430\n",
      "Epoch val: g_loss = 0.016642, d_loss = 0.162034, content_loss = 0.014320, advers_loss = 2.322096\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 17\n",
      "Epoch generator loss = 0.015514, discriminator loss = 0.183001\n",
      "Epoch val: g_loss = 0.017482, d_loss = 0.174838, content_loss = 0.014296, advers_loss = 3.185837\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 18\n",
      "Epoch generator loss = 0.015570, discriminator loss = 0.187318\n",
      "Epoch val: g_loss = 0.017354, d_loss = 0.172812, content_loss = 0.014290, advers_loss = 3.064573\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 19\n",
      "Epoch generator loss = 0.015771, discriminator loss = 0.177803\n",
      "Epoch val: g_loss = 0.017662, d_loss = 0.186811, content_loss = 0.014355, advers_loss = 3.306866\n",
      "Epoch took 71.30 seconds\n",
      "\n",
      "Epoch: 20\n",
      "Epoch generator loss = 0.015849, discriminator loss = 0.175525\n",
      "Epoch val: g_loss = 0.017762, d_loss = 0.158423, content_loss = 0.014220, advers_loss = 3.542088\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#This is old cell...Use as a baseline...Don't run it again!\n",
    "gen_model_copy = gen_model\n",
    "gen_model_gan, disc_model_gan = train(gen_model_copy, disc_model, epochs=20, batch_size=128, alpha_advers=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e8c6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 23:13:13.058785: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch generator loss = 0.013959, discriminator loss = 0.690694\n",
      "Epoch val: g_loss = 0.013202, d_loss = 0.687033, content_loss = 0.012513, advers_loss = 0.688950\n",
      "Epoch took 77.75 seconds\n",
      "\n",
      "Epoch: 2\n",
      "Epoch generator loss = 0.011227, discriminator loss = 0.678161\n",
      "Epoch val: g_loss = 0.012624, d_loss = 0.666862, content_loss = 0.011940, advers_loss = 0.684485\n",
      "Epoch took 71.49 seconds\n",
      "\n",
      "Epoch: 3\n",
      "Epoch generator loss = 0.010499, discriminator loss = 0.655292\n",
      "Epoch val: g_loss = 0.012619, d_loss = 0.643332, content_loss = 0.011914, advers_loss = 0.705594\n",
      "Epoch took 71.12 seconds\n",
      "\n",
      "Epoch: 4\n",
      "Epoch generator loss = 0.010140, discriminator loss = 0.634736\n",
      "Epoch val: g_loss = 0.012720, d_loss = 0.621345, content_loss = 0.011954, advers_loss = 0.766147\n",
      "Epoch took 70.96 seconds\n",
      "\n",
      "Epoch: 5\n",
      "Epoch generator loss = 0.010020, discriminator loss = 0.615354\n",
      "Epoch val: g_loss = 0.012659, d_loss = 0.614914, content_loss = 0.011993, advers_loss = 0.665825\n",
      "Epoch took 71.05 seconds\n",
      "\n",
      "Epoch: 6\n",
      "Epoch generator loss = 0.010001, discriminator loss = 0.602778\n",
      "Epoch val: g_loss = 0.012862, d_loss = 0.586689, content_loss = 0.012010, advers_loss = 0.852876\n",
      "Epoch took 71.20 seconds\n",
      "\n",
      "Epoch: 7\n",
      "Epoch generator loss = 0.010042, discriminator loss = 0.588390\n",
      "Epoch val: g_loss = 0.012905, d_loss = 0.578721, content_loss = 0.012031, advers_loss = 0.873173\n",
      "Epoch took 71.18 seconds\n",
      "\n",
      "Epoch: 8\n",
      "Epoch generator loss = 0.010075, discriminator loss = 0.585828\n",
      "Epoch val: g_loss = 0.013023, d_loss = 0.569685, content_loss = 0.012056, advers_loss = 0.967435\n",
      "Epoch took 71.14 seconds\n",
      "\n",
      "Epoch: 9\n",
      "Epoch generator loss = 0.010101, discriminator loss = 0.566453\n",
      "Epoch val: g_loss = 0.013094, d_loss = 0.562746, content_loss = 0.012088, advers_loss = 1.006726\n",
      "Epoch took 71.16 seconds\n",
      "\n",
      "Epoch: 10\n",
      "Epoch generator loss = 0.010136, discriminator loss = 0.571554\n",
      "Epoch val: g_loss = 0.013300, d_loss = 0.576248, content_loss = 0.012111, advers_loss = 1.189198\n",
      "Epoch took 71.17 seconds\n",
      "\n",
      "Epoch: 11\n",
      "Epoch generator loss = 0.010153, discriminator loss = 0.558906\n",
      "Epoch val: g_loss = 0.013167, d_loss = 0.548133, content_loss = 0.012159, advers_loss = 1.008747\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 12\n",
      "Epoch generator loss = 0.010178, discriminator loss = 0.558427\n",
      "Epoch val: g_loss = 0.013352, d_loss = 0.562278, content_loss = 0.012178, advers_loss = 1.174422\n",
      "Epoch took 71.16 seconds\n",
      "\n",
      "Epoch: 13\n",
      "Epoch generator loss = 0.010203, discriminator loss = 0.578331\n",
      "Epoch val: g_loss = 0.013229, d_loss = 0.541524, content_loss = 0.012224, advers_loss = 1.004953\n",
      "Epoch took 71.14 seconds\n",
      "\n",
      "Epoch: 14\n",
      "Epoch generator loss = 0.010184, discriminator loss = 0.542945\n",
      "Epoch val: g_loss = 0.013366, d_loss = 0.537891, content_loss = 0.012305, advers_loss = 1.060403\n",
      "Epoch took 71.14 seconds\n",
      "\n",
      "Epoch: 15\n",
      "Epoch generator loss = 0.010238, discriminator loss = 0.546188\n",
      "Epoch val: g_loss = 0.013335, d_loss = 0.533845, content_loss = 0.012322, advers_loss = 1.013767\n",
      "Epoch took 71.15 seconds\n",
      "\n",
      "Epoch: 16\n",
      "Epoch generator loss = 0.010270, discriminator loss = 0.547425\n",
      "Epoch val: g_loss = 0.013502, d_loss = 0.542438, content_loss = 0.012433, advers_loss = 1.069760\n",
      "Epoch took 71.16 seconds\n",
      "\n",
      "Epoch: 17\n",
      "Epoch generator loss = 0.010347, discriminator loss = 0.550832\n",
      "Epoch val: g_loss = 0.013603, d_loss = 0.569624, content_loss = 0.012324, advers_loss = 1.278863\n",
      "Epoch took 71.16 seconds\n",
      "\n",
      "Epoch: 18\n",
      "Epoch generator loss = 0.010465, discriminator loss = 0.551621\n",
      "Epoch val: g_loss = 0.013335, d_loss = 0.531277, content_loss = 0.012365, advers_loss = 0.969885\n",
      "Epoch took 71.19 seconds\n",
      "\n",
      "Epoch: 19\n",
      "Epoch generator loss = 0.010424, discriminator loss = 0.541638\n",
      "Epoch val: g_loss = 0.013511, d_loss = 0.547077, content_loss = 0.012305, advers_loss = 1.206367\n",
      "Epoch took 71.16 seconds\n",
      "\n",
      "Epoch: 20\n",
      "Epoch generator loss = 0.010464, discriminator loss = 0.569379\n",
      "Epoch val: g_loss = 0.013430, d_loss = 0.537255, content_loss = 0.012347, advers_loss = 1.083139\n",
      "Epoch took 71.17 seconds\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#This is another old cell...Use as a baseline...Don't run it again!\n",
    "gen_model_copy = gen_model\n",
    "gen_model_gan, disc_model_gan = train(gen_model_copy, disc_model, epochs=20, batch_size=128, alpha_advers=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de7b6f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Epoch: 1\n",
      "Epoch generator loss = 0.017364, discriminator loss = 0.575698\n",
      "Epoch val: g_loss = 0.014610, d_loss = 0.483025, content_loss = 0.013723, advers_loss = 0.886674\n",
      "Epoch took 71.34 seconds\n",
      "\n",
      "Epoch: 2\n",
      "Epoch generator loss = 0.013059, discriminator loss = 0.493132\n",
      "Epoch val: g_loss = 0.013709, d_loss = 0.500946, content_loss = 0.012655, advers_loss = 1.054259\n",
      "Epoch took 71.64 seconds\n",
      "\n",
      "Epoch: 3\n",
      "Epoch generator loss = 0.012047, discriminator loss = 0.507576\n",
      "Epoch val: g_loss = 0.013299, d_loss = 0.516748, content_loss = 0.012349, advers_loss = 0.949914\n",
      "Epoch took 71.17 seconds\n",
      "\n",
      "Epoch: 4\n",
      "Epoch generator loss = 0.011527, discriminator loss = 0.522405\n",
      "Epoch val: g_loss = 0.013220, d_loss = 0.534289, content_loss = 0.012265, advers_loss = 0.955288\n",
      "Epoch took 70.93 seconds\n",
      "\n",
      "Epoch: 5\n",
      "Epoch generator loss = 0.011245, discriminator loss = 0.527741\n",
      "Epoch val: g_loss = 0.013343, d_loss = 0.548862, content_loss = 0.012327, advers_loss = 1.015619\n",
      "Epoch took 71.00 seconds\n",
      "\n",
      "Epoch: 6\n",
      "Epoch generator loss = 0.011055, discriminator loss = 0.533305\n",
      "Epoch val: g_loss = 0.013348, d_loss = 0.545604, content_loss = 0.012348, advers_loss = 1.000717\n",
      "Epoch took 71.15 seconds\n",
      "\n",
      "Epoch: 7\n",
      "Epoch generator loss = 0.010894, discriminator loss = 0.532092\n",
      "Epoch val: g_loss = 0.013386, d_loss = 0.539360, content_loss = 0.012384, advers_loss = 1.002233\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 8\n",
      "Epoch generator loss = 0.010770, discriminator loss = 0.528485\n",
      "Epoch val: g_loss = 0.013480, d_loss = 0.534032, content_loss = 0.012436, advers_loss = 1.043647\n",
      "Epoch took 71.20 seconds\n",
      "\n",
      "Epoch: 9\n",
      "Epoch generator loss = 0.010678, discriminator loss = 0.528405\n",
      "Epoch val: g_loss = 0.013509, d_loss = 0.528405, content_loss = 0.012475, advers_loss = 1.034015\n",
      "Epoch took 71.17 seconds\n",
      "\n",
      "Epoch: 10\n",
      "Epoch generator loss = 0.010613, discriminator loss = 0.526231\n",
      "Epoch val: g_loss = 0.013542, d_loss = 0.521528, content_loss = 0.012496, advers_loss = 1.045647\n",
      "Epoch took 71.20 seconds\n",
      "\n",
      "Epoch: 11\n",
      "Epoch generator loss = 0.010573, discriminator loss = 0.524349\n",
      "Epoch val: g_loss = 0.013572, d_loss = 0.517138, content_loss = 0.012508, advers_loss = 1.064355\n",
      "Epoch took 71.19 seconds\n",
      "\n",
      "Epoch: 12\n",
      "Epoch generator loss = 0.010546, discriminator loss = 0.519097\n",
      "Epoch val: g_loss = 0.013588, d_loss = 0.516037, content_loss = 0.012518, advers_loss = 1.070223\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 13\n",
      "Epoch generator loss = 0.010525, discriminator loss = 0.512728\n",
      "Epoch val: g_loss = 0.013603, d_loss = 0.518555, content_loss = 0.012522, advers_loss = 1.080852\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 14\n",
      "Epoch generator loss = 0.010510, discriminator loss = 0.509435\n",
      "Epoch val: g_loss = 0.013634, d_loss = 0.517244, content_loss = 0.012505, advers_loss = 1.129121\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 15\n",
      "Epoch generator loss = 0.010500, discriminator loss = 0.511151\n",
      "Epoch val: g_loss = 0.013710, d_loss = 0.521272, content_loss = 0.012484, advers_loss = 1.226713\n",
      "Epoch took 71.30 seconds\n",
      "\n",
      "Epoch: 16\n",
      "Epoch generator loss = 0.010486, discriminator loss = 0.508975\n",
      "Epoch val: g_loss = 0.013638, d_loss = 0.518052, content_loss = 0.012482, advers_loss = 1.155501\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 17\n",
      "Epoch generator loss = 0.010481, discriminator loss = 0.505445\n",
      "Epoch val: g_loss = 0.013559, d_loss = 0.516810, content_loss = 0.012494, advers_loss = 1.065188\n",
      "Epoch took 71.21 seconds\n",
      "\n",
      "Epoch: 18\n",
      "Epoch generator loss = 0.010487, discriminator loss = 0.504328\n",
      "Epoch val: g_loss = 0.013641, d_loss = 0.507111, content_loss = 0.012475, advers_loss = 1.166091\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 19\n",
      "Epoch generator loss = 0.010489, discriminator loss = 0.496837\n",
      "Epoch val: g_loss = 0.013542, d_loss = 0.488397, content_loss = 0.012466, advers_loss = 1.075493\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 20\n",
      "Epoch generator loss = 0.010508, discriminator loss = 0.495614\n",
      "Epoch val: g_loss = 0.013454, d_loss = 0.491037, content_loss = 0.012476, advers_loss = 0.978347\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 21\n",
      "Epoch generator loss = 0.010529, discriminator loss = 0.498501\n",
      "Epoch val: g_loss = 0.013668, d_loss = 0.483710, content_loss = 0.012473, advers_loss = 1.195212\n",
      "Epoch took 71.21 seconds\n",
      "\n",
      "Epoch: 22\n",
      "Epoch generator loss = 0.010538, discriminator loss = 0.492783\n",
      "Epoch val: g_loss = 0.013800, d_loss = 0.492076, content_loss = 0.012483, advers_loss = 1.317058\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 23\n",
      "Epoch generator loss = 0.010558, discriminator loss = 0.493446\n",
      "Epoch val: g_loss = 0.013615, d_loss = 0.481122, content_loss = 0.012509, advers_loss = 1.105710\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 24\n",
      "Epoch generator loss = 0.010565, discriminator loss = 0.484346\n",
      "Epoch val: g_loss = 0.013675, d_loss = 0.485055, content_loss = 0.012543, advers_loss = 1.132164\n",
      "Epoch took 71.21 seconds\n",
      "\n",
      "Epoch: 25\n",
      "Epoch generator loss = 0.010587, discriminator loss = 0.483321\n",
      "Epoch val: g_loss = 0.013808, d_loss = 0.480917, content_loss = 0.012552, advers_loss = 1.256028\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 26\n",
      "Epoch generator loss = 0.010609, discriminator loss = 0.479227\n",
      "Epoch val: g_loss = 0.013799, d_loss = 0.484219, content_loss = 0.012573, advers_loss = 1.225847\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 27\n",
      "Epoch generator loss = 0.010631, discriminator loss = 0.477369\n",
      "Epoch val: g_loss = 0.013709, d_loss = 0.476107, content_loss = 0.012577, advers_loss = 1.131210\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 28\n",
      "Epoch generator loss = 0.010661, discriminator loss = 0.482294\n",
      "Epoch val: g_loss = 0.013849, d_loss = 0.482010, content_loss = 0.012588, advers_loss = 1.261041\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 29\n",
      "Epoch generator loss = 0.010683, discriminator loss = 0.477276\n",
      "Epoch val: g_loss = 0.013841, d_loss = 0.482785, content_loss = 0.012632, advers_loss = 1.209387\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 30\n",
      "Epoch generator loss = 0.010726, discriminator loss = 0.474679\n",
      "Epoch val: g_loss = 0.013765, d_loss = 0.476504, content_loss = 0.012678, advers_loss = 1.087164\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 31\n",
      "Epoch generator loss = 0.010766, discriminator loss = 0.473889\n",
      "Epoch val: g_loss = 0.013797, d_loss = 0.463389, content_loss = 0.012695, advers_loss = 1.102232\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 32\n",
      "Epoch generator loss = 0.010797, discriminator loss = 0.473610\n",
      "Epoch val: g_loss = 0.013746, d_loss = 0.469524, content_loss = 0.012738, advers_loss = 1.007908\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 33\n",
      "Epoch generator loss = 0.010826, discriminator loss = 0.470678\n",
      "Epoch val: g_loss = 0.013818, d_loss = 0.478865, content_loss = 0.012854, advers_loss = 0.964058\n",
      "Epoch took 71.21 seconds\n",
      "\n",
      "Epoch: 34\n",
      "Epoch generator loss = 0.010878, discriminator loss = 0.471285\n",
      "Epoch val: g_loss = 0.013999, d_loss = 0.488058, content_loss = 0.013039, advers_loss = 0.959775\n",
      "Epoch took 71.19 seconds\n",
      "\n",
      "Epoch: 35\n",
      "Epoch generator loss = 0.010911, discriminator loss = 0.473216\n",
      "Epoch val: g_loss = 0.014158, d_loss = 0.484770, content_loss = 0.012694, advers_loss = 1.464676\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 36\n",
      "Epoch generator loss = 0.010858, discriminator loss = 0.468259\n",
      "Epoch val: g_loss = 0.014102, d_loss = 0.463154, content_loss = 0.012702, advers_loss = 1.399925\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 37\n",
      "Epoch generator loss = 0.010820, discriminator loss = 0.464367\n",
      "Epoch val: g_loss = 0.013983, d_loss = 0.457977, content_loss = 0.012730, advers_loss = 1.252892\n",
      "Epoch took 71.20 seconds\n",
      "\n",
      "Epoch: 38\n",
      "Epoch generator loss = 0.010796, discriminator loss = 0.464948\n",
      "Epoch val: g_loss = 0.014064, d_loss = 0.473526, content_loss = 0.012754, advers_loss = 1.309165\n",
      "Epoch took 71.20 seconds\n",
      "\n",
      "Epoch: 39\n",
      "Epoch generator loss = 0.010799, discriminator loss = 0.467422\n",
      "Epoch val: g_loss = 0.013997, d_loss = 0.460687, content_loss = 0.012763, advers_loss = 1.233657\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 40\n",
      "Epoch generator loss = 0.010804, discriminator loss = 0.466156\n",
      "Epoch val: g_loss = 0.014062, d_loss = 0.454384, content_loss = 0.012792, advers_loss = 1.270493\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 41\n",
      "Epoch generator loss = 0.010826, discriminator loss = 0.468355\n",
      "Epoch val: g_loss = 0.014162, d_loss = 0.452990, content_loss = 0.012851, advers_loss = 1.310571\n",
      "Epoch took 71.18 seconds\n",
      "\n",
      "Epoch: 42\n",
      "Epoch generator loss = 0.010872, discriminator loss = 0.471070\n",
      "Epoch val: g_loss = 0.014338, d_loss = 0.464497, content_loss = 0.013010, advers_loss = 1.328589\n",
      "Epoch took 71.21 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43\n",
      "Epoch generator loss = 0.010957, discriminator loss = 0.473624\n",
      "Epoch val: g_loss = 0.013990, d_loss = 0.474965, content_loss = 0.012781, advers_loss = 1.208763\n",
      "Epoch took 71.21 seconds\n",
      "\n",
      "Epoch: 44\n",
      "Epoch generator loss = 0.011019, discriminator loss = 0.465066\n",
      "Epoch val: g_loss = 0.014281, d_loss = 0.476811, content_loss = 0.012904, advers_loss = 1.377354\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 45\n",
      "Epoch generator loss = 0.011107, discriminator loss = 0.461701\n",
      "Epoch val: g_loss = 0.014512, d_loss = 0.482131, content_loss = 0.013198, advers_loss = 1.313444\n",
      "Epoch took 71.49 seconds\n",
      "\n",
      "Epoch: 46\n",
      "Epoch generator loss = 0.011182, discriminator loss = 0.463264\n",
      "Epoch val: g_loss = 0.014340, d_loss = 0.498312, content_loss = 0.012887, advers_loss = 1.453358\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 47\n",
      "Epoch generator loss = 0.011015, discriminator loss = 0.471588\n",
      "Epoch val: g_loss = 0.014259, d_loss = 0.483507, content_loss = 0.012950, advers_loss = 1.308823\n",
      "Epoch took 71.31 seconds\n",
      "\n",
      "Epoch: 48\n",
      "Epoch generator loss = 0.010955, discriminator loss = 0.470662\n",
      "Epoch val: g_loss = 0.014069, d_loss = 0.478480, content_loss = 0.012996, advers_loss = 1.073172\n",
      "Epoch took 71.29 seconds\n",
      "\n",
      "Epoch: 49\n",
      "Epoch generator loss = 0.010923, discriminator loss = 0.469689\n",
      "Epoch val: g_loss = 0.014162, d_loss = 0.475162, content_loss = 0.012930, advers_loss = 1.232085\n",
      "Epoch took 71.29 seconds\n",
      "\n",
      "Epoch: 50\n",
      "Epoch generator loss = 0.010906, discriminator loss = 0.470635\n",
      "Epoch val: g_loss = 0.014213, d_loss = 0.473177, content_loss = 0.012909, advers_loss = 1.303678\n",
      "Epoch took 71.32 seconds\n",
      "\n",
      "Epoch: 51\n",
      "Epoch generator loss = 0.010908, discriminator loss = 0.474474\n",
      "Epoch val: g_loss = 0.014185, d_loss = 0.474345, content_loss = 0.012913, advers_loss = 1.271814\n",
      "Epoch took 71.31 seconds\n",
      "\n",
      "Epoch: 52\n",
      "Epoch generator loss = 0.010911, discriminator loss = 0.474994\n",
      "Epoch val: g_loss = 0.014139, d_loss = 0.485901, content_loss = 0.012956, advers_loss = 1.183550\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 53\n",
      "Epoch generator loss = 0.010918, discriminator loss = 0.475440\n",
      "Epoch val: g_loss = 0.014217, d_loss = 0.485418, content_loss = 0.012963, advers_loss = 1.254633\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 54\n",
      "Epoch generator loss = 0.010927, discriminator loss = 0.478891\n",
      "Epoch val: g_loss = 0.014395, d_loss = 0.493381, content_loss = 0.012969, advers_loss = 1.425589\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 55\n",
      "Epoch generator loss = 0.010937, discriminator loss = 0.477901\n",
      "Epoch val: g_loss = 0.014433, d_loss = 0.499669, content_loss = 0.012992, advers_loss = 1.440833\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 56\n",
      "Epoch generator loss = 0.010954, discriminator loss = 0.482551\n",
      "Epoch val: g_loss = 0.014133, d_loss = 0.476145, content_loss = 0.013009, advers_loss = 1.124804\n",
      "Epoch took 71.30 seconds\n",
      "\n",
      "Epoch: 57\n",
      "Epoch generator loss = 0.010973, discriminator loss = 0.478913\n",
      "Epoch val: g_loss = 0.014171, d_loss = 0.483145, content_loss = 0.013038, advers_loss = 1.133647\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 58\n",
      "Epoch generator loss = 0.010994, discriminator loss = 0.481996\n",
      "Epoch val: g_loss = 0.014294, d_loss = 0.484941, content_loss = 0.013069, advers_loss = 1.224306\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 59\n",
      "Epoch generator loss = 0.011020, discriminator loss = 0.486657\n",
      "Epoch val: g_loss = 0.014456, d_loss = 0.491563, content_loss = 0.013142, advers_loss = 1.314068\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 60\n",
      "Epoch generator loss = 0.011041, discriminator loss = 0.492920\n",
      "Epoch val: g_loss = 0.014723, d_loss = 0.537608, content_loss = 0.013160, advers_loss = 1.563531\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 61\n",
      "Epoch generator loss = 0.011069, discriminator loss = 0.498185\n",
      "Epoch val: g_loss = 0.014306, d_loss = 0.489580, content_loss = 0.013176, advers_loss = 1.130464\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 62\n",
      "Epoch generator loss = 0.011148, discriminator loss = 0.490739\n",
      "Epoch val: g_loss = 0.014171, d_loss = 0.494715, content_loss = 0.013219, advers_loss = 0.951975\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 63\n",
      "Epoch generator loss = 0.011230, discriminator loss = 0.489501\n",
      "Epoch val: g_loss = 0.014290, d_loss = 0.490680, content_loss = 0.013304, advers_loss = 0.986075\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 64\n",
      "Epoch generator loss = 0.011245, discriminator loss = 0.492162\n",
      "Epoch val: g_loss = 0.014241, d_loss = 0.472425, content_loss = 0.013126, advers_loss = 1.115645\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 65\n",
      "Epoch generator loss = 0.011251, discriminator loss = 0.498653\n",
      "Epoch val: g_loss = 0.014423, d_loss = 0.488608, content_loss = 0.013115, advers_loss = 1.308817\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 66\n",
      "Epoch generator loss = 0.011388, discriminator loss = 0.505470\n",
      "Epoch val: g_loss = 0.014449, d_loss = 0.505867, content_loss = 0.013516, advers_loss = 0.932996\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 67\n",
      "Epoch generator loss = 0.011526, discriminator loss = 0.500518\n",
      "Epoch val: g_loss = 0.014033, d_loss = 0.509635, content_loss = 0.013147, advers_loss = 0.885829\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 68\n",
      "Epoch generator loss = 0.011386, discriminator loss = 0.501868\n",
      "Epoch val: g_loss = 0.014058, d_loss = 0.517850, content_loss = 0.013182, advers_loss = 0.876164\n",
      "Epoch took 71.32 seconds\n",
      "\n",
      "Epoch: 69\n",
      "Epoch generator loss = 0.011301, discriminator loss = 0.504936\n",
      "Epoch val: g_loss = 0.014098, d_loss = 0.502938, content_loss = 0.013154, advers_loss = 0.944392\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 70\n",
      "Epoch generator loss = 0.011240, discriminator loss = 0.510993\n",
      "Epoch val: g_loss = 0.014050, d_loss = 0.503037, content_loss = 0.013125, advers_loss = 0.924846\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 71\n",
      "Epoch generator loss = 0.011194, discriminator loss = 0.510614\n",
      "Epoch val: g_loss = 0.014143, d_loss = 0.500451, content_loss = 0.013154, advers_loss = 0.988957\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 72\n",
      "Epoch generator loss = 0.011170, discriminator loss = 0.512630\n",
      "Epoch val: g_loss = 0.014138, d_loss = 0.506270, content_loss = 0.013173, advers_loss = 0.964270\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 73\n",
      "Epoch generator loss = 0.011152, discriminator loss = 0.512309\n",
      "Epoch val: g_loss = 0.014138, d_loss = 0.502987, content_loss = 0.013180, advers_loss = 0.958500\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 74\n",
      "Epoch generator loss = 0.011142, discriminator loss = 0.513760\n",
      "Epoch val: g_loss = 0.014115, d_loss = 0.502355, content_loss = 0.013184, advers_loss = 0.931315\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 75\n",
      "Epoch generator loss = 0.011144, discriminator loss = 0.513632\n",
      "Epoch val: g_loss = 0.014130, d_loss = 0.502757, content_loss = 0.013193, advers_loss = 0.936366\n",
      "Epoch took 71.39 seconds\n",
      "\n",
      "Epoch: 76\n",
      "Epoch generator loss = 0.011156, discriminator loss = 0.515069\n",
      "Epoch val: g_loss = 0.014127, d_loss = 0.507894, content_loss = 0.013214, advers_loss = 0.912990\n",
      "Epoch took 71.30 seconds\n",
      "\n",
      "Epoch: 77\n",
      "Epoch generator loss = 0.011161, discriminator loss = 0.515807\n",
      "Epoch val: g_loss = 0.014167, d_loss = 0.509854, content_loss = 0.013239, advers_loss = 0.927367\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 78\n",
      "Epoch generator loss = 0.011160, discriminator loss = 0.517276\n",
      "Epoch val: g_loss = 0.014163, d_loss = 0.513111, content_loss = 0.013237, advers_loss = 0.925847\n",
      "Epoch took 71.31 seconds\n",
      "\n",
      "Epoch: 79\n",
      "Epoch generator loss = 0.011163, discriminator loss = 0.516374\n",
      "Epoch val: g_loss = 0.014166, d_loss = 0.506878, content_loss = 0.013216, advers_loss = 0.950451\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 80\n",
      "Epoch generator loss = 0.011177, discriminator loss = 0.516957\n",
      "Epoch val: g_loss = 0.014220, d_loss = 0.501315, content_loss = 0.013227, advers_loss = 0.993353\n",
      "Epoch took 71.33 seconds\n",
      "\n",
      "Epoch: 81\n",
      "Epoch generator loss = 0.011235, discriminator loss = 0.517256\n",
      "Epoch val: g_loss = 0.014227, d_loss = 0.501203, content_loss = 0.013241, advers_loss = 0.985510\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 82\n",
      "Epoch generator loss = 0.011380, discriminator loss = 0.513366\n",
      "Epoch val: g_loss = 0.014106, d_loss = 0.491319, content_loss = 0.013169, advers_loss = 0.936374\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 83\n",
      "Epoch generator loss = 0.011435, discriminator loss = 0.518149\n",
      "Epoch val: g_loss = 0.014505, d_loss = 0.509135, content_loss = 0.013262, advers_loss = 1.243197\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 84\n",
      "Epoch generator loss = 0.011432, discriminator loss = 0.518442\n",
      "Epoch val: g_loss = 0.014158, d_loss = 0.523257, content_loss = 0.013291, advers_loss = 0.866993\n",
      "Epoch took 71.26 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85\n",
      "Epoch generator loss = 0.011403, discriminator loss = 0.514446\n",
      "Epoch val: g_loss = 0.014015, d_loss = 0.528680, content_loss = 0.013201, advers_loss = 0.813569\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 86\n",
      "Epoch generator loss = 0.011351, discriminator loss = 0.512347\n",
      "Epoch val: g_loss = 0.014078, d_loss = 0.512271, content_loss = 0.013144, advers_loss = 0.933782\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 87\n",
      "Epoch generator loss = 0.011288, discriminator loss = 0.517924\n",
      "Epoch val: g_loss = 0.014093, d_loss = 0.515251, content_loss = 0.013174, advers_loss = 0.919740\n",
      "Epoch took 71.27 seconds\n",
      "\n",
      "Epoch: 88\n",
      "Epoch generator loss = 0.011291, discriminator loss = 0.517844\n",
      "Epoch val: g_loss = 0.014116, d_loss = 0.514136, content_loss = 0.013201, advers_loss = 0.915710\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 89\n",
      "Epoch generator loss = 0.011325, discriminator loss = 0.516837\n",
      "Epoch val: g_loss = 0.014176, d_loss = 0.511293, content_loss = 0.013250, advers_loss = 0.926291\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 90\n",
      "Epoch generator loss = 0.011376, discriminator loss = 0.516395\n",
      "Epoch val: g_loss = 0.014123, d_loss = 0.516006, content_loss = 0.013271, advers_loss = 0.851700\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 91\n",
      "Epoch generator loss = 0.011395, discriminator loss = 0.514013\n",
      "Epoch val: g_loss = 0.014188, d_loss = 0.506145, content_loss = 0.013301, advers_loss = 0.886939\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 92\n",
      "Epoch generator loss = 0.011435, discriminator loss = 0.513888\n",
      "Epoch val: g_loss = 0.014253, d_loss = 0.508674, content_loss = 0.013366, advers_loss = 0.886709\n",
      "Epoch took 71.28 seconds\n",
      "\n",
      "Epoch: 93\n",
      "Epoch generator loss = 0.011464, discriminator loss = 0.514315\n",
      "Epoch val: g_loss = 0.014067, d_loss = 0.508135, content_loss = 0.013144, advers_loss = 0.923866\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 94\n",
      "Epoch generator loss = 0.011401, discriminator loss = 0.514105\n",
      "Epoch val: g_loss = 0.014195, d_loss = 0.502618, content_loss = 0.013212, advers_loss = 0.983034\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 95\n",
      "Epoch generator loss = 0.011379, discriminator loss = 0.516498\n",
      "Epoch val: g_loss = 0.014295, d_loss = 0.503105, content_loss = 0.013364, advers_loss = 0.931341\n",
      "Epoch took 71.22 seconds\n",
      "\n",
      "Epoch: 96\n",
      "Epoch generator loss = 0.011374, discriminator loss = 0.515407\n",
      "Epoch val: g_loss = 0.014374, d_loss = 0.507683, content_loss = 0.013464, advers_loss = 0.910708\n",
      "Epoch took 71.23 seconds\n",
      "\n",
      "Epoch: 97\n",
      "Epoch generator loss = 0.011390, discriminator loss = 0.513716\n",
      "Epoch val: g_loss = 0.014431, d_loss = 0.515488, content_loss = 0.013562, advers_loss = 0.869488\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Epoch: 98\n",
      "Epoch generator loss = 0.011451, discriminator loss = 0.512321\n",
      "Epoch val: g_loss = 0.014524, d_loss = 0.515460, content_loss = 0.013669, advers_loss = 0.854442\n",
      "Epoch took 71.25 seconds\n",
      "\n",
      "Epoch: 99\n",
      "Epoch generator loss = 0.011567, discriminator loss = 0.510069\n",
      "Epoch val: g_loss = 0.014692, d_loss = 0.495942, content_loss = 0.013819, advers_loss = 0.873171\n",
      "Epoch took 71.26 seconds\n",
      "\n",
      "Epoch: 100\n",
      "Epoch generator loss = 0.011623, discriminator loss = 0.513216\n",
      "Epoch val: g_loss = 0.014695, d_loss = 0.482774, content_loss = 0.013561, advers_loss = 1.134487\n",
      "Epoch took 71.24 seconds\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#This is another old cell which continues the last cell...Use as a baseline...Don't run it again!\n",
    "gen_model_gan, disc_model_gan = train(gen_model_gan, disc_model_gan, epochs=100, batch_size=128, alpha_advers=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1945d0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "gen_model_gan.save('gan/v2/gen_model_gan_v2.h5')\n",
    "disc_model_gan.save('gan/v2/disc_model_gan_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdaad37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "gen_model_reopen = tf.keras.models.load_model('gan/v2/gen_model_gan_v2.h5')\n",
    "disc_model_reopen = tf.keras.models.load_model('gan/v2/disc_model_gan_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35aaed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Epoch: 1\n",
      "Epoch generator loss = 0.016659, discriminator loss = 0.535702\n",
      "Epoch val: g_loss = 0.014914, d_loss = 0.380175, content_loss = 0.013659, advers_loss = 1.255487\n",
      "Epoch took 71.95 seconds\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "gen_model_reopen, disc_model_reopen = train(gen_model_reopen, disc_model_reopen, epochs=1, batch_size=128, alpha_advers=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23c32f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(x_HR, x_SR, d_SR, alpha_advers=0.001):\n",
    "    \n",
    "    content_loss = tf.reduce_mean((x_HR - x_SR)**2)\n",
    "    g_advers_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_SR, labels=tf.ones_like(d_SR)))\n",
    "    g_loss = content_loss + alpha_advers * g_advers_loss\n",
    "    \n",
    "    return g_loss, content_loss, g_advers_loss\n",
    "\n",
    "def discriminator_loss(d_HR, d_SR):\n",
    "    \n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=tf.concat([d_HR, d_SR], axis=0),\n",
    "                                                                  labels=tf.concat([tf.ones_like(d_HR), tf.zeros_like(d_SR)], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26b46485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "@tf.function\n",
    "def train_step(generator, discriminator, generator_optimizer, discriminator_optimizer, batch_LR, batch_HR, alpha_advers=0.001):\n",
    "    \n",
    "    g_count = 0\n",
    "    d_loss = tf.constant(0.0)\n",
    "    d_HR = discriminator(batch_HR, training=False)\n",
    "    while(d_loss < tf.constant(0.45) and g_count < 20):\n",
    "        g_count += 1\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            batch_SR = generator(batch_LR, training=True)\n",
    "            d_SR = discriminator(batch_SR, training=False)\n",
    "            g_loss, content_loss, g_advers_loss = generator_loss(batch_HR, batch_SR, d_SR, alpha_advers=alpha_advers)\n",
    "\n",
    "        grad_of_gen = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(grad_of_gen, generator.trainable_variables))\n",
    "        d_loss = discriminator_loss(d_HR, d_SR)\n",
    "\n",
    "    d_count = 0\n",
    "    d_loss = tf.constant(100.0)\n",
    "    while(d_loss > tf.constant(0.65) and d_count < 20):\n",
    "        d_count += 1\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            batch_SR = generator(batch_LR, training=False)\n",
    "            d_HR = discriminator(batch_HR, training=True)\n",
    "            d_SR = discriminator(batch_SR, training=True)\n",
    "            d_loss = discriminator_loss(d_HR, d_SR)\n",
    "\n",
    "        grad_of_disc = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "        discriminator_optimizer.apply_gradients(zip(grad_of_disc, discriminator.trainable_variables))\n",
    "        \n",
    "    return g_loss, d_loss, g_count, d_count\n",
    "\n",
    "    \n",
    "def train(gen_model, disc_model, epochs=20, batch_size=128, alpha_advers=0.001):\n",
    "    '''\n",
    "        This method trains the generator and disctiminator adversarially\n",
    "        Notice the two model should be argument of this function\n",
    "        output: generator model and discriminator model\n",
    "    '''\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "    batch_count = tf.data.experimental.cardinality(train_dataset)\n",
    "    \n",
    "    g_opt = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    d_opt = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    # Start training\n",
    "    print('Training network ...')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print('Epoch: %d' %(epoch))\n",
    "        start_time = time()\n",
    "        epoch_g_loss, epoch_d_loss, N, g_count_tot, d_count_tot = 0, 0, 0, 0, 0\n",
    "        \n",
    "        for batch_idx, (batch_LR, batch_HR) in enumerate(train_dataset):\n",
    "            N_batch = batch_LR.shape[0]\n",
    "            g_loss, d_loss, g_count, d_count \\\n",
    "                = train_step(gen_model, disc_model, g_opt, d_opt, batch_LR, batch_HR, alpha_advers)\n",
    "            \n",
    "            epoch_g_loss += g_loss * N_batch\n",
    "            epoch_d_loss += d_loss * N_batch\n",
    "            N += N_batch\n",
    "            g_count_tot += g_count\n",
    "            d_count_tot += d_count\n",
    "\n",
    "        epoch_g_loss = epoch_g_loss / N       \n",
    "        epoch_d_loss = epoch_d_loss / N       \n",
    "        \n",
    "        val_SR = gen_model.predict(x_val, verbose=0)\n",
    "        val_d_HR = disc_model.predict(y_val, verbose=0)\n",
    "        val_d_SR = disc_model.predict(val_SR, verbose=0)\n",
    "        \n",
    "        val_g_loss, val_content_loss, val_advers_loss = generator_loss(y_val, val_SR, val_d_SR, alpha_advers)\n",
    "        val_d_loss = discriminator_loss(val_d_HR, val_d_SR)\n",
    "        \n",
    "        print('Epoch generator loss = %.6f, discriminator loss = %.6f, g_count = %d, d_count = %d' %(epoch_g_loss, epoch_d_loss, g_count_tot, d_count_tot))\n",
    "        print('Epoch val: g_loss = %.6f, d_loss = %.6f, content_loss = %.6f, advers_loss = %.6f' \\\n",
    "              %(val_g_loss, val_d_loss, val_content_loss, val_advers_loss))\n",
    "        print('Epoch took %.2f seconds\\n' %(time() - start_time), flush=True)\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "    return gen_model, disc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5df7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network ...\n",
      "Epoch: 1\n",
      "Epoch generator loss = 0.013088, discriminator loss = 0.469322, g_count = 213, d_count = 40\n",
      "Epoch val: g_loss = 0.013804, d_loss = 0.489812, content_loss = 0.013066, advers_loss = 0.738212\n",
      "Epoch took 174.13 seconds\n",
      "\n",
      "Epoch: 2\n",
      "Epoch generator loss = 0.011306, discriminator loss = 0.462603, g_count = 245, d_count = 40\n",
      "Epoch val: g_loss = 0.014872, d_loss = 0.460794, content_loss = 0.013433, advers_loss = 1.439021\n",
      "Epoch took 187.67 seconds\n",
      "\n",
      "Epoch: 3\n",
      "Epoch generator loss = 0.011590, discriminator loss = 0.461018, g_count = 193, d_count = 40\n",
      "Epoch val: g_loss = 0.014561, d_loss = 0.431687, content_loss = 0.013468, advers_loss = 1.092899\n",
      "Epoch took 153.30 seconds\n",
      "\n",
      "Epoch: 4\n",
      "Epoch generator loss = 0.011671, discriminator loss = 0.458729, g_count = 200, d_count = 40\n",
      "Epoch val: g_loss = 0.014865, d_loss = 0.456652, content_loss = 0.013603, advers_loss = 1.261903\n",
      "Epoch took 157.56 seconds\n",
      "\n",
      "Epoch: 5\n",
      "Epoch generator loss = 0.011773, discriminator loss = 0.458742, g_count = 201, d_count = 40\n",
      "Epoch val: g_loss = 0.015039, d_loss = 0.449020, content_loss = 0.013438, advers_loss = 1.600190\n",
      "Epoch took 158.28 seconds\n",
      "\n",
      "Epoch: 6\n",
      "Epoch generator loss = 0.011951, discriminator loss = 0.458816, g_count = 154, d_count = 40\n",
      "Epoch val: g_loss = 0.014696, d_loss = 0.421567, content_loss = 0.013632, advers_loss = 1.064131\n",
      "Epoch took 126.43 seconds\n",
      "\n",
      "Epoch: 7\n",
      "Epoch generator loss = 0.011962, discriminator loss = 0.459073, g_count = 223, d_count = 40\n",
      "Epoch val: g_loss = 0.015059, d_loss = 0.446897, content_loss = 0.013589, advers_loss = 1.469855\n",
      "Epoch took 173.35 seconds\n",
      "\n",
      "Epoch: 8\n",
      "Epoch generator loss = 0.012094, discriminator loss = 0.456009, g_count = 170, d_count = 40\n",
      "Epoch val: g_loss = 0.014932, d_loss = 0.421841, content_loss = 0.013725, advers_loss = 1.206808\n",
      "Epoch took 137.31 seconds\n",
      "\n",
      "Epoch: 9\n",
      "Epoch generator loss = 0.012130, discriminator loss = 0.458001, g_count = 200, d_count = 40\n",
      "Epoch val: g_loss = 0.014927, d_loss = 0.412212, content_loss = 0.013674, advers_loss = 1.253088\n",
      "Epoch took 158.11 seconds\n",
      "\n",
      "Epoch: 10\n",
      "Epoch generator loss = 0.012183, discriminator loss = 0.456214, g_count = 169, d_count = 40\n",
      "Epoch val: g_loss = 0.015304, d_loss = 0.444449, content_loss = 0.013824, advers_loss = 1.479708\n",
      "Epoch took 136.42 seconds\n",
      "\n",
      "Epoch: 11\n",
      "Epoch generator loss = 0.012262, discriminator loss = 0.459041, g_count = 187, d_count = 40\n",
      "Epoch val: g_loss = 0.015608, d_loss = 0.461395, content_loss = 0.013945, advers_loss = 1.662634\n",
      "Epoch took 148.60 seconds\n",
      "\n",
      "Epoch: 12\n",
      "Epoch generator loss = 0.012325, discriminator loss = 0.457076, g_count = 186, d_count = 40\n",
      "Epoch val: g_loss = 0.014997, d_loss = 0.439525, content_loss = 0.013847, advers_loss = 1.149955\n",
      "Epoch took 148.46 seconds\n",
      "\n",
      "Epoch: 13\n",
      "Epoch generator loss = 0.012316, discriminator loss = 0.456325, g_count = 197, d_count = 40\n",
      "Epoch val: g_loss = 0.015599, d_loss = 0.447752, content_loss = 0.013985, advers_loss = 1.614006\n",
      "Epoch took 155.91 seconds\n",
      "\n",
      "Epoch: 14\n",
      "Epoch generator loss = 0.012430, discriminator loss = 0.457429, g_count = 178, d_count = 40\n",
      "Epoch val: g_loss = 0.015166, d_loss = 0.409511, content_loss = 0.013937, advers_loss = 1.228496\n",
      "Epoch took 142.83 seconds\n",
      "\n",
      "Epoch: 15\n",
      "Epoch generator loss = 0.012361, discriminator loss = 0.462299, g_count = 218, d_count = 40\n",
      "Epoch val: g_loss = 0.015323, d_loss = 0.456423, content_loss = 0.014078, advers_loss = 1.245017\n",
      "Epoch took 170.43 seconds\n",
      "\n",
      "Epoch: 16\n",
      "Epoch generator loss = 0.012527, discriminator loss = 0.463661, g_count = 180, d_count = 40\n",
      "Epoch val: g_loss = 0.015047, d_loss = 0.428265, content_loss = 0.013935, advers_loss = 1.111614\n",
      "Epoch took 144.20 seconds\n",
      "\n",
      "Epoch: 17\n",
      "Epoch generator loss = 0.012527, discriminator loss = 0.456131, g_count = 187, d_count = 40\n",
      "Epoch val: g_loss = 0.015091, d_loss = 0.410633, content_loss = 0.013938, advers_loss = 1.152705\n",
      "Epoch took 149.06 seconds\n",
      "\n",
      "Epoch: 18\n",
      "Epoch generator loss = 0.012472, discriminator loss = 0.461103, g_count = 218, d_count = 40\n",
      "Epoch val: g_loss = 0.015673, d_loss = 0.447721, content_loss = 0.013941, advers_loss = 1.732399\n",
      "Epoch took 170.41 seconds\n",
      "\n",
      "Epoch: 19\n",
      "Epoch generator loss = 0.012540, discriminator loss = 0.460438, g_count = 192, d_count = 40\n",
      "Epoch val: g_loss = 0.015461, d_loss = 0.422798, content_loss = 0.013928, advers_loss = 1.532460\n",
      "Epoch took 152.50 seconds\n",
      "\n",
      "Epoch: 20\n",
      "Epoch generator loss = 0.012557, discriminator loss = 0.459160, g_count = 198, d_count = 40\n",
      "Epoch val: g_loss = 0.016074, d_loss = 0.517267, content_loss = 0.014034, advers_loss = 2.039909\n",
      "Epoch took 156.22 seconds\n",
      "\n",
      "Epoch: 21\n",
      "Epoch generator loss = 0.012608, discriminator loss = 0.465976, g_count = 200, d_count = 40\n",
      "Epoch val: g_loss = 0.015479, d_loss = 0.441295, content_loss = 0.014156, advers_loss = 1.322594\n",
      "Epoch took 158.21 seconds\n",
      "\n",
      "Epoch: 22\n",
      "Epoch generator loss = 0.012596, discriminator loss = 0.467725, g_count = 212, d_count = 40\n",
      "Epoch val: g_loss = 0.015636, d_loss = 0.445328, content_loss = 0.014005, advers_loss = 1.630657\n",
      "Epoch took 166.26 seconds\n",
      "\n",
      "Epoch: 23\n",
      "Epoch generator loss = 0.012592, discriminator loss = 0.462719, g_count = 196, d_count = 40\n",
      "Epoch val: g_loss = 0.015874, d_loss = 0.474601, content_loss = 0.014116, advers_loss = 1.758632\n",
      "Epoch took 154.99 seconds\n",
      "\n",
      "Epoch: 24\n",
      "Epoch generator loss = 0.012675, discriminator loss = 0.463762, g_count = 188, d_count = 40\n",
      "Epoch val: g_loss = 0.015742, d_loss = 0.417412, content_loss = 0.014157, advers_loss = 1.585585\n",
      "Epoch took 149.71 seconds\n",
      "\n",
      "Epoch: 25\n",
      "Epoch generator loss = 0.012677, discriminator loss = 0.463360, g_count = 201, d_count = 40\n",
      "Epoch val: g_loss = 0.016037, d_loss = 0.474642, content_loss = 0.014194, advers_loss = 1.842828\n",
      "Epoch took 158.48 seconds\n",
      "\n",
      "Epoch: 26\n",
      "Epoch generator loss = 0.012699, discriminator loss = 0.466285, g_count = 188, d_count = 40\n",
      "Epoch val: g_loss = 0.016381, d_loss = 0.522989, content_loss = 0.014233, advers_loss = 2.147316\n",
      "Epoch took 149.56 seconds\n",
      "\n",
      "Epoch: 27\n",
      "Epoch generator loss = 0.012744, discriminator loss = 0.467019, g_count = 189, d_count = 40\n",
      "Epoch val: g_loss = 0.015750, d_loss = 0.417836, content_loss = 0.014024, advers_loss = 1.726106\n",
      "Epoch took 150.25 seconds\n",
      "\n",
      "Epoch: 28\n",
      "Epoch generator loss = 0.012743, discriminator loss = 0.462773, g_count = 192, d_count = 40\n",
      "Epoch val: g_loss = 0.015886, d_loss = 0.459644, content_loss = 0.014005, advers_loss = 1.880738\n",
      "Epoch took 152.33 seconds\n",
      "\n",
      "Epoch: 29\n",
      "Epoch generator loss = 0.012714, discriminator loss = 0.464571, g_count = 204, d_count = 40\n",
      "Epoch val: g_loss = 0.016009, d_loss = 0.460926, content_loss = 0.014010, advers_loss = 1.998186\n",
      "Epoch took 160.63 seconds\n",
      "\n",
      "Epoch: 30\n",
      "Epoch generator loss = 0.012778, discriminator loss = 0.463175, g_count = 178, d_count = 40\n",
      "Epoch val: g_loss = 0.015520, d_loss = 0.345500, content_loss = 0.013904, advers_loss = 1.615779\n",
      "Epoch took 142.90 seconds\n",
      "\n",
      "Epoch: 31\n",
      "Epoch generator loss = 0.012753, discriminator loss = 0.464241, g_count = 207, d_count = 40\n",
      "Epoch val: g_loss = 0.015791, d_loss = 0.409848, content_loss = 0.014057, advers_loss = 1.734696\n",
      "Epoch took 162.62 seconds\n",
      "\n",
      "Epoch: 32\n",
      "Epoch generator loss = 0.012819, discriminator loss = 0.464831, g_count = 169, d_count = 40\n",
      "Epoch val: g_loss = 0.015936, d_loss = 0.397159, content_loss = 0.013938, advers_loss = 1.998811\n",
      "Epoch took 136.74 seconds\n",
      "\n",
      "Epoch: 33\n",
      "Epoch generator loss = 0.012767, discriminator loss = 0.464575, g_count = 205, d_count = 40\n",
      "Epoch val: g_loss = 0.016018, d_loss = 0.452652, content_loss = 0.014131, advers_loss = 1.887281\n",
      "Epoch took 161.23 seconds\n",
      "\n",
      "Epoch: 34\n",
      "Epoch generator loss = 0.012779, discriminator loss = 0.470531, g_count = 202, d_count = 40\n",
      "Epoch val: g_loss = 0.016289, d_loss = 0.426272, content_loss = 0.014388, advers_loss = 1.900708\n",
      "Epoch took 159.22 seconds\n",
      "\n",
      "Epoch: 35\n",
      "Epoch generator loss = 0.012768, discriminator loss = 0.469771, g_count = 199, d_count = 40\n",
      "Epoch val: g_loss = 0.015995, d_loss = 0.442335, content_loss = 0.014097, advers_loss = 1.898139\n",
      "Epoch took 157.11 seconds\n",
      "\n",
      "Epoch: 36\n",
      "Epoch generator loss = 0.012853, discriminator loss = 0.467308, g_count = 178, d_count = 40\n",
      "Epoch val: g_loss = 0.015549, d_loss = 0.401876, content_loss = 0.014223, advers_loss = 1.325159\n",
      "Epoch took 142.90 seconds\n",
      "\n",
      "Epoch: 37\n"
     ]
    }
   ],
   "source": [
    "gen_model_reopen, disc_model_reopen = train(gen_model_reopen, disc_model_reopen, epochs=100, batch_size=128, alpha_advers=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7230be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
