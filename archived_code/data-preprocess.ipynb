{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26042f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_era5 = xr.load_dataset('data/perdigao_era5_2020.nc')\n",
    "ds_era5['vel100'] = np.sqrt(ds_era5['u100'] ** 2 +  ds_era5['v100'] ** 2)\n",
    "ds_era5['vel100'].attrs = {'long_name': '100 meter horizontal wind speed', 'units': 'm/s'}\n",
    "ds_era5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917050ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_low_res_pre = xr.load_dataset('data/perdigao_low_res_1H_2020.nc')\n",
    "ds_low_res_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4059c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_high_res_pre = xr.load_dataset('data/perdigao_high_res_1H_2020.nc')\n",
    "ds_high_res_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is nan\n",
    "for var_name in ds_era5.data_vars:\n",
    "    print(\"ds_era5 \", var_name, np.isnan(ds_era5[var_name]).any().to_numpy())\n",
    "#check if there is nan\n",
    "for var_name in ds_low_res_pre.data_vars:\n",
    "    print(\"ds_low_res_pre \", var_name, np.isnan(ds_low_res_pre[var_name]).any().to_numpy())\n",
    "#check if there is nan\n",
    "for var_name in ds_high_res_pre.data_vars:\n",
    "    print(\"ds_high_res_pre \", var_name, np.isnan(ds_high_res_pre[var_name]).any().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880afa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the pattern where nan shows up\n",
    "# The pattern should be that, for a given time, we see nan on all sites for all variables\n",
    "\n",
    "low_res_nan_t_idx_list = []\n",
    "for var_name in ds_low_res_pre.data_vars:\n",
    "    if var_name == \"absolute_height\":\n",
    "        continue\n",
    "    print(\"Doing \", var_name, \" for ds_low_res_pre\")\n",
    "    mask_low = np.isnan(ds_low_res_pre[var_name])\n",
    "    nan_idx_tuple = np.where(mask_low == True)\n",
    "    nan_t_idx = np.unique(nan_idx_tuple[0])\n",
    "    print(nan_idx_tuple[0].shape, nan_t_idx.shape)\n",
    "    low_res_nan_t_idx_list.append(nan_t_idx)\n",
    "#    print(nan_t_idx, '\\n')\n",
    "for i in range(len(low_res_nan_t_idx_list) -1):\n",
    "    assert(np.array_equal(low_res_nan_t_idx_list[i], low_res_nan_t_idx_list[i+1]))\n",
    "    \n",
    "high_res_nan_t_idx_list = []\n",
    "for var_name in ds_high_res_pre.data_vars:\n",
    "    if var_name == \"absolute_height\":\n",
    "        continue\n",
    "    print(\"Doing \", var_name, \" for ds_high_res_pre\")\n",
    "    mask_high = np.isnan(ds_high_res_pre[var_name])\n",
    "    nan_idx_tuple = np.where(mask_high == True)\n",
    "    nan_t_idx = np.unique(nan_idx_tuple[0])\n",
    "    print(nan_idx_tuple[0].shape, nan_t_idx.shape)\n",
    "    high_res_nan_t_idx_list.append(nan_t_idx)\n",
    "#    print(nan_t_idx, '\\n')\n",
    "for i in range(len(high_res_nan_t_idx_list) -1):\n",
    "    assert(np.array_equal(high_res_nan_t_idx_list[i], high_res_nan_t_idx_list[i+1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "# In this step we try to remove those timeslices where we only have nan. This is critical in DL\n",
    "\n",
    "# First find the union of nan_t_idx of low/high res input ds\n",
    "print(\"Low, \", low_res_nan_t_idx_list[0].shape, low_res_nan_t_idx_list[0])\n",
    "print(\"High, \", high_res_nan_t_idx_list[0].shape, high_res_nan_t_idx_list[0])\n",
    "nan_t_idx_union = np.union1d(low_res_nan_t_idx_list[0], high_res_nan_t_idx_list[0])\n",
    "print(\"Union, \", nan_t_idx_union.shape, nan_t_idx_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then drop those data in both ds, first do low res\n",
    "\n",
    "print(ds_low_res_pre)\n",
    "ds_low_res = ds_low_res_pre.drop_isel(time=nan_t_idx_union)\n",
    "print(ds_low_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then drop those data in both ds, next do high res\n",
    "\n",
    "print(ds_high_res_pre)\n",
    "ds_high_res = ds_high_res_pre.drop_isel(time=nan_t_idx_union)\n",
    "print(ds_high_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263613fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next make sure there is no nan anymore\n",
    "\n",
    "for var_name in ds_low_res.data_vars:\n",
    "    print(\"ds_low_res \", var_name, np.isnan(ds_low_res[var_name]).any().to_numpy())\n",
    "for var_name in ds_high_res.data_vars:\n",
    "    print(\"ds_high_res \", var_name, np.isnan(ds_high_res[var_name]).any().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally save to disk\n",
    "\n",
    "ds_low_res.to_netcdf('processed_data/perdigao_low_res_1H_2020.nc')\n",
    "ds_high_res.to_netcdf('processed_data/perdigao_high_res_1H_2020.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28ec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we can open it again and it is the same\n",
    "\n",
    "ds_low_res_reopen = xr.load_dataset('processed_data/perdigao_low_res_1H_2020.nc')\n",
    "ds_high_res_reopen = xr.load_dataset('processed_data/perdigao_high_res_1H_2020.nc')\n",
    "print(ds_low_res.equals(ds_low_res_reopen))\n",
    "print(ds_high_res.equals(ds_high_res_reopen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf8733",
   "metadata": {},
   "source": [
    "# Compute the statistics of low and high resolution data for GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lr_u = ds_low_res[\"u\"].mean().to_numpy()\n",
    "mean_lr_v = ds_low_res[\"v\"].mean().to_numpy()\n",
    "mean_hr_u = ds_high_res[\"u\"].mean().to_numpy()\n",
    "mean_hr_v = ds_high_res[\"v\"].mean().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_lr_u)\n",
    "print(mean_lr_v)\n",
    "print(mean_hr_u)\n",
    "print(mean_hr_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604323a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev_lr_u = ds_low_res[\"u\"].std().to_numpy()\n",
    "stddev_lr_v = ds_low_res[\"v\"].std().to_numpy()\n",
    "stddev_hr_u = ds_high_res[\"u\"].std().to_numpy()\n",
    "stddev_hr_v = ds_high_res[\"v\"].std().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stddev_lr_u)\n",
    "print(stddev_lr_v)\n",
    "print(stddev_hr_u)\n",
    "print(stddev_hr_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8780bf",
   "metadata": {},
   "source": [
    "# Standardrize the dataset for GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_high_res_std_u = ( ds_high_res[\"u\"] - mean_hr_u ) / stddev_hr_u\n",
    "da_high_res_std_v = ( ds_high_res[\"v\"] - mean_hr_v ) / stddev_hr_v\n",
    "print(da_high_res_std_u.mean().to_numpy())\n",
    "print(da_high_res_std_v.mean().to_numpy())\n",
    "print(da_high_res_std_u.std().to_numpy())\n",
    "print(da_high_res_std_v.std().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd63748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so weird... If I stack them with axis=-1, then result of std and mean will be incorrect!\n",
    "np_hr_std_pre = np.stack((da_high_res_std_u.to_numpy(), da_high_res_std_v.to_numpy()), axis=0)\n",
    "print(np_hr_std_pre.shape)\n",
    "\n",
    "np_hr_std = np_hr_std_pre.transpose(1,2,3,0)\n",
    "print(np_hr_std.shape)\n",
    "\n",
    "print(np_hr_std.std(axis=(0,1,2)))\n",
    "print(np_hr_std.mean(axis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec471d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_low_res_std_u = ( ds_low_res[\"u\"] - mean_lr_u ) / stddev_lr_u\n",
    "da_low_res_std_v = ( ds_low_res[\"v\"] - mean_lr_v ) / stddev_lr_v\n",
    "print(da_low_res_std_u.mean().to_numpy())\n",
    "print(da_low_res_std_v.mean().to_numpy())\n",
    "print(da_low_res_std_u.std().to_numpy())\n",
    "print(da_low_res_std_v.std().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf465d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so weird... If I stack them with axis=-1, then result of std and mean will be incorrect!\n",
    "np_lr_std_pre = np.stack((da_low_res_std_u.to_numpy(), da_low_res_std_v.to_numpy()), axis=0)\n",
    "print(np_lr_std_pre.shape)\n",
    "\n",
    "np_lr_std = np_lr_std_pre.transpose(1,2,3,0)\n",
    "print(np_lr_std.shape)\n",
    "\n",
    "print(np_lr_std.std(axis=(0,1,2)))\n",
    "print(np_lr_std.mean(axis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a8edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mean = np.array([mean_lr_u, mean_lr_v])\n",
    "hr_mean = np.array([mean_hr_u, mean_hr_v])\n",
    "lr_stddev = np.array([stddev_lr_u, stddev_lr_v])\n",
    "hr_stddev = np.array([stddev_hr_u, stddev_hr_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('processed_data/np_gan_standard.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"np_lr\",  data=np_lr_std)\n",
    "    hf.create_dataset(\"np_hr\",  data=np_hr_std)\n",
    "    hf.create_dataset(\"np_lr_mean\",  data=lr_mean)\n",
    "    hf.create_dataset(\"np_hr_mean\",  data=hr_mean)\n",
    "    hf.create_dataset(\"np_lr_stddev\",  data=lr_stddev)\n",
    "    hf.create_dataset(\"np_hr_stddev\",  data=hr_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('processed_data/np_gan_standard.h5', 'r') as hf:\n",
    "    data_lr = hf['np_lr'][:]\n",
    "    data_lr_mean = hf['np_lr_mean'][:]\n",
    "    data_lr_stddev = hf['np_lr_stddev'][:]\n",
    "    data_hr = hf['np_hr'][:]\n",
    "    data_hr_mean = hf['np_hr_mean'][:]\n",
    "    data_hr_stddev = hf['np_hr_stddev'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array_equal(np_lr_std, data_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa710d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array_equal(np_hr_std, data_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7114fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lr_reopen = data_lr * data_lr_stddev + data_lr_mean\n",
    "print(np.max(np_lr_reopen[:,:,:,0] - ds_low_res[\"u\"].to_numpy()))\n",
    "print(np.max(np_lr_reopen[:,:,:,1] - ds_low_res[\"v\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_hr_reopen = data_hr * data_hr_stddev + data_hr_mean\n",
    "print(np.max(np_hr_reopen[:,:,:,0] - ds_high_res[\"u\"].to_numpy()))\n",
    "print(np.max(np_hr_reopen[:,:,:,1] - ds_high_res[\"v\"].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71f3ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
