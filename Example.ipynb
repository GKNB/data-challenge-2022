{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60fb7440-14b9-4c2b-adbb-94d44e433e3f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This script is an example to run the code for the data challenge with explanations. Details of each step can be found in each section. Functions used are from the ``` ./lib ``` folder. \n",
    "\n",
    "The structure of the code is:\n",
    "1. Data preprocessing:\n",
    "    - Removing NANs in the data\n",
    "    - Standardrization\n",
    "2. Training: \n",
    "    - Dimension reduction with autoencoder\n",
    "    - GAN/CNN for super-resolution (SR)\n",
    "    \n",
    "## Code structure:\n",
    "- Data preprocessing:\n",
    "    * ``` preprocess.py ``` provides the functions needed for data preprocessing\n",
    "- GAN for super-resolution\n",
    "    * ``` models.py ``` provides the models needed in GAN\n",
    "    * ``` GAN_class.py ``` contains the class defined for full GAN training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8dbda-c13e-4617-8d20-e4dc3b187e34",
   "metadata": {},
   "source": [
    "# Code for running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edadce7-68a0-4e10-9e44-e9cfb9c2a81e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2438ec33-7c8b-4252-ad78-88c5c3f3f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"./lib\")\n",
    "from preprocess import *\n",
    "from models import *\n",
    "from GAN_class import *\n",
    "from AE_class import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf4540-2b00-409b-90e8-c12353cb8735",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4f14ee-af01-474f-b135-6548ecf5a60d",
   "metadata": {},
   "source": [
    "The function ``` data_preprocess ``` will take the list of data sets and parameters required in the preprocessing.\n",
    "\n",
    "The parameters are explained below:\n",
    "\n",
    "1. For NAN removal:\n",
    "    - ``` \"nan_dim_along\" ```: the dimension along which we remove NAN data\n",
    "    - ``` \"nan_data_irrelevant\" ```: the irrelevant data to detect NAN\n",
    "    - ``` \"output_folder\" ```: folder for data output\n",
    "    - ``` \"file_format\" ```: the file name format used for saving NAN-removed data\n",
    "2. For Standardrization:\n",
    "    - ``` \"stat_dim\" ```: the statistical dimension of the data, used for mean, stddev, etc.\n",
    "    - ``` \"std_file_format\" ```: the file name format used for standardrized data file h5\n",
    "    - ``` \"std_data_format\" ```: the data name format used for h5 standardrized data \n",
    "    - ``` \"std_data_list\" ```: list of data to be standardrized\n",
    "    - ``` \"std_dataset_list\" ```: list of data sets to be standardrized\n",
    "    - ``` \"num_error_tolerance\" ```: numerical tolerance for passing the standardrization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecd2eda-f516-41e4-abb0-787909629a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up parameters\n",
    "output_folder = \"../data/preprocessed/\"\n",
    "file_format= \"%s\"\n",
    "std_file_format = \"np_gan_standard\"\n",
    "std_data_format = \"np_%s\"\n",
    "parameters = {\"nan_dim_along\":\"time\", \"nan_data_irrelevant\":\"absolute_height\", \\\n",
    "              \"output_folder\":output_folder,\"file_format\":file_format, \\\n",
    "              \"stat_dim\" : \"time\",\\\n",
    "              \"std_file_format\":std_file_format, \"std_data_format\":std_data_format,\\\n",
    "              \"std_data_list\":[\"u\",\"v\"], \\\n",
    "              \"std_dataset_list\":[\"perdigao_low_res_1H_2020\",\"perdigao_high_res_1H_2020\"],\\\n",
    "              \"num_error_tolerance\":1e-5}\n",
    "list_of_data_set_path=['../data/perdigao_era5_2020.nc', '../data/perdigao_low_res_1H_2020.nc', '../data/perdigao_high_res_1H_2020.nc' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a13f1e-4ce9-4809-b0ad-a2cab043b38f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataSets by loading files:['../data/perdigao_era5_2020.nc', '../data/perdigao_low_res_1H_2020.nc', '../data/perdigao_high_res_1H_2020.nc']\n",
      "Removing NAN indices along dimension:time\n",
      "WARNING! This will change the oringal DataSets!\n",
      "Searching NAN in DataSets: dict_keys(['perdigao_era5_2020', 'perdigao_low_res_1H_2020', 'perdigao_high_res_1H_2020'])...\n",
      "Checking nan pattern of variable: u100  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: v100  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: t2m  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: i10fg  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "NAN pattern along dimension: time, is CONSISTENT for all other coords, with absolute_height excluded\n",
      "Checking nan pattern of variable: std  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (1446912,), along (157,) time indicies\n",
      "Checking nan pattern of variable: temp  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (1446912,), along (157,) time indicies\n",
      "Checking nan pattern of variable: v  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (1446912,), along (157,) time indicies\n",
      "Checking nan pattern of variable: vel  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (1446912,), along (157,) time indicies\n",
      "NAN pattern along dimension: time, is CONSISTENT for all other coords, with absolute_height excluded\n",
      "Checking nan pattern of variable: std  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (9363456,), along (254,) time indicies\n",
      "Checking nan pattern of variable: temp  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (9363456,), along (254,) time indicies\n",
      "Checking nan pattern of variable: v  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (9363456,), along (254,) time indicies\n",
      "Checking nan pattern of variable: vel  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (9363456,), along (254,) time indicies\n",
      "NAN pattern along dimension: time, is CONSISTENT for all other coords, with absolute_height excluded\n",
      "nan indices to be removed are: [1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621\n",
      " 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1944 1945 1946 1947\n",
      " 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961\n",
      " 1962 1963 1964 1965 1966 1967 4165 4166 4167 4168 4169 4170 4171 4172\n",
      " 4173 4174 4175 4189 4190 4191 4192 4193 4194 4195 4196 4197 4198 4199\n",
      " 4453 4454 4455 4456 4457 4458 4459 4460 4461 4462 4463 4476 4477 4478\n",
      " 4479 4480 4481 4482 4483 4484 4485 4486 4487 4500 4501 4502 4503 4504\n",
      " 4505 4506 4507 4508 4509 4510 4511 4525 4526 4527 4528 4529 4530 4531\n",
      " 4532 4533 4534 4535 4669 4670 4671 4672 4673 4674 4675 4676 4677 4678\n",
      " 4679 4693 4694 4695 4696 4697 4698 4699 4700 4701 4702 4703 4718 4719\n",
      " 4720 4721 4722 4723 4724 4725 4726 4727 4740 4741 4742 4743 4744 4745\n",
      " 4746 4747 4748 4749 4750 4751 4764 4765 4766 4767 4768 4769 4770 4771\n",
      " 4772 4773 4774 4775 4788 4789 4790 4791 4792 4793 4794 4795 4796 4797\n",
      " 4798 4799 4813 4814 4815 4816 4817 4818 4819 4820 4821 4822 4823 4837\n",
      " 4838 4839 4840 4841 4842 4843 4844 4845 4846 4847 4980 4981 4982 4983\n",
      " 4984 4985 4986 4987 4988 4989 4990 4991 5053 5054 5055 5056 5057 5058\n",
      " 5059 5060 5061 5062 5063 5221 5222 5223 5224 5225 5226 5227 5228 5229\n",
      " 5230 5231 8568 8569 8570 8571 8572 8573 8574 8575 8576 8577 8578 8579\n",
      " 8580 8581 8582 8583 8584 8585 8586 8587 8588 8589 8590 8591]\n",
      "Checking if there's NAN in datasets:dict_keys(['perdigao_era5_2020', 'perdigao_low_res_1H_2020', 'perdigao_high_res_1H_2020'])\n",
      "Searching NAN in DataSets: dict_keys(['perdigao_era5_2020', 'perdigao_low_res_1H_2020', 'perdigao_high_res_1H_2020'])...\n",
      "Checking nan pattern of variable: u100  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: v100  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: t2m  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: i10fg  for DataSet: perdigao_era5_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "NAN pattern along dimension: time, is CONSISTENT for all other coords, with absolute_height excluded\n",
      "Checking nan pattern of variable: std  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: temp  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: v  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: vel  for DataSet: perdigao_low_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "NAN pattern along dimension: time, is CONSISTENT for all other coords, with absolute_height excluded\n",
      "Checking nan pattern of variable: std  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: temp  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: v  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "Checking nan pattern of variable: vel  for DataSet: perdigao_high_res_1H_2020\n",
      "Total number of NAN: (0,), along (0,) time indicies\n",
      "NAN pattern along dimension: time, is CONSISTENT for all other coords, with absolute_height excluded\n",
      "NAN all get removed! Saving preprocessed data!\n",
      "Saving DataSet: perdigao_era5_2020 to ../data/preprocessed/perdigao_era5_2020.nc\n",
      "Saving DataSet: perdigao_low_res_1H_2020 to ../data/preprocessed/perdigao_low_res_1H_2020.nc\n",
      "Saving DataSet: perdigao_high_res_1H_2020 to ../data/preprocessed/perdigao_high_res_1H_2020.nc\n",
      "Loading again DataSet: perdigao_era5_2020 from ../data/preprocessed/perdigao_era5_2020.nc\n",
      "Loading again DataSet: perdigao_low_res_1H_2020 from ../data/preprocessed/perdigao_low_res_1H_2020.nc\n",
      "Loading again DataSet: perdigao_high_res_1H_2020 from ../data/preprocessed/perdigao_high_res_1H_2020.nc\n",
      "DataSets:dict_keys(['perdigao_era5_2020', 'perdigao_low_res_1H_2020', 'perdigao_high_res_1H_2020']) are all IO_safe.\n",
      "Standardrizing data set: perdigao_low_res_1H_2020\n",
      "\tStandardrizing data:u\n",
      "shape check: PASSED. This program expect data with 3 dimensions:[time, x, y] for 2D training.\n",
      "\tmean_shape:(), stddev_shape:(), std_shape:(8520, 96, 96)\n",
      "\tStandardrizing data:v\n",
      "shape check: PASSED. This program expect data with 3 dimensions:[time, x, y] for 2D training.\n",
      "\tmean_shape:(), stddev_shape:(), std_shape:(8520, 96, 96)\n",
      "\tStacking standardrized data: ['u', 'v']\n",
      "\t\tStacking data u, stdrzd with mean:2.1677807993114584e-08, std:1.0000008344650269\n",
      "\t\tStacking data v, stdrzd with mean:-7.172083655859751e-07, std:1.000001072883606\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\t\tStacking data u, mean with mean:0.7051483988761902, std:0.0\n",
      "\t\tStacking data v, mean with mean:-1.014777421951294, std:0.0\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\t\tStacking data u, std with mean:3.1869051456451416, std:0.0\n",
      "\t\tStacking data v, std with mean:2.882791519165039, std:0.0\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\tStacking raw data: ['u', 'v']\n",
      "\t\tStacking data u, raw with mean:0.7051483988761902, std:3.1869051456451416\n",
      "\t\tStacking data v, raw with mean:-1.014777421951294, std:2.882791519165039\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\tstacked: mean_shape:(2,), stddev_shape:(2,), std_shape:(8520, 96, 96, 2), raw_shape:(8520, 96, 96, 2)\n",
      "\tstacked std stat(over all other dimensions (0, 1, 2)): mean:[ 2.1677808e-08 -7.1720837e-07], stddev:[1.0000008 1.0000011]\n",
      "Standardrizing data set: perdigao_high_res_1H_2020\n",
      "\tStandardrizing data:u\n",
      "shape check: PASSED. This program expect data with 3 dimensions:[time, x, y] for 2D training.\n",
      "\tmean_shape:(), stddev_shape:(), std_shape:(8520, 192, 192)\n",
      "\tStandardrizing data:v\n",
      "shape check: PASSED. This program expect data with 3 dimensions:[time, x, y] for 2D training.\n",
      "\tmean_shape:(), stddev_shape:(), std_shape:(8520, 192, 192)\n",
      "\tStacking standardrized data: ['u', 'v']\n",
      "\t\tStacking data u, stdrzd with mean:-1.8022865333477966e-07, std:0.9999976754188538\n",
      "\t\tStacking data v, stdrzd with mean:-9.072684861166636e-07, std:1.000000238418579\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\t\tStacking data u, mean with mean:0.7011979818344116, std:0.0\n",
      "\t\tStacking data v, mean with mean:-1.0068085193634033, std:0.0\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\t\tStacking data u, std with mean:3.149406909942627, std:0.0\n",
      "\t\tStacking data v, std with mean:2.8781955242156982, std:0.0\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\tStacking raw data: ['u', 'v']\n",
      "\t\tStacking data u, raw with mean:0.7011979818344116, std:3.149406909942627\n",
      "\t\tStacking data v, raw with mean:-1.0068085193634033, std:2.8781955242156982\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\tstacked: mean_shape:(2,), stddev_shape:(2,), std_shape:(8520, 192, 192, 2), raw_shape:(8520, 192, 192, 2)\n",
      "\tstacked std stat(over all other dimensions (0, 1, 2)): mean:[-1.8022865e-07 -9.0726849e-07], stddev:[0.9999977 1.0000002]\n",
      "Checking standardrized data set: perdigao_low_res_1H_2020\n",
      "\tReconstruct stacked unstandardrized data!\n",
      "\t data_set_recovered = std_data[(8520, 96, 96, 2)] * stddev[(2,)] + mean[(2,)]\n",
      "\t\tStacking data u, raw with mean:0.7051483988761902, std:3.1869051456451416\n",
      "\t\tStacking data v, raw with mean:-1.014777421951294, std:2.882791519165039\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\tNumerical error of standardrization is: 1.9073486328125e-06\n",
      "Checking standardrized data set: perdigao_high_res_1H_2020\n",
      "\tReconstruct stacked unstandardrized data!\n",
      "\t data_set_recovered = std_data[(8520, 192, 192, 2)] * stddev[(2,)] + mean[(2,)]\n",
      "\t\tStacking data u, raw with mean:0.7011979818344116, std:3.149406909942627\n",
      "\t\tStacking data v, raw with mean:-1.0068085193634033, std:2.8781955242156982\n",
      "\tStacked 2 data in data_dict: ['u', 'v']\n",
      "\tNumerical error of standardrization is: 1.9073486328125e-06\n",
      "Standardrization check for standardrized data set: perdigao_high_res_1H_2020, PASSED\n",
      "Saving data np_perdigao_low_res_1H_2020_std to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "Saving data np_perdigao_low_res_1H_2020_mean to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "Saving data np_perdigao_low_res_1H_2020_stddev to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "Saving data np_perdigao_low_res_1H_2020_raw to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "Saving data np_perdigao_high_res_1H_2020_std to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "Saving data np_perdigao_high_res_1H_2020_mean to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "Saving data np_perdigao_high_res_1H_2020_stddev to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "Saving data np_perdigao_high_res_1H_2020_raw to h5 file ../data/preprocessed/np_gan_standard.h5\n",
      "IO check of data set:dict_keys(['perdigao_low_res_1H_2020', 'perdigao_high_res_1H_2020']) to h5 file ../data/preprocessed/np_gan_standard.h5 PASSED\n",
      "Successfully preprocessed all the data!\n"
     ]
    }
   ],
   "source": [
    "#start data_preprocess\n",
    "data_preprocess(list_of_data_set_path, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02a5bd-9d06-4570-a1bc-c4241ff7311b",
   "metadata": {},
   "source": [
    "### Example for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5f1ed1-5dfc-426a-a186-3bb6d1718d97",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in file ../data/preprocessed/np_gan_standard.h5 are: \n",
      " ['np_perdigao_high_res_1H_2020_mean', 'np_perdigao_high_res_1H_2020_raw', 'np_perdigao_high_res_1H_2020_std', 'np_perdigao_high_res_1H_2020_stddev', 'np_perdigao_low_res_1H_2020_mean', 'np_perdigao_low_res_1H_2020_raw', 'np_perdigao_low_res_1H_2020_std', 'np_perdigao_low_res_1H_2020_stddev']\n",
      "Examining data np_perdigao_high_res_1H_2020_mean\n",
      "Examining data np_perdigao_high_res_1H_2020_raw\n",
      "Examining data np_perdigao_high_res_1H_2020_std\n",
      "Examining data np_perdigao_high_res_1H_2020_stddev\n",
      "Examining data np_perdigao_low_res_1H_2020_mean\n",
      "Examining data np_perdigao_low_res_1H_2020_raw\n",
      "Examining data np_perdigao_low_res_1H_2020_std\n",
      "Loading data np_perdigao_low_res_1H_2020_std from file ../data/preprocessed/np_gan_standard.h5\n",
      "Data in file ../data/preprocessed/np_gan_standard.h5 are: \n",
      " ['np_perdigao_high_res_1H_2020_mean', 'np_perdigao_high_res_1H_2020_raw', 'np_perdigao_high_res_1H_2020_std', 'np_perdigao_high_res_1H_2020_stddev', 'np_perdigao_low_res_1H_2020_mean', 'np_perdigao_low_res_1H_2020_raw', 'np_perdigao_low_res_1H_2020_std', 'np_perdigao_low_res_1H_2020_stddev']\n",
      "Examining data np_perdigao_high_res_1H_2020_mean\n",
      "Examining data np_perdigao_high_res_1H_2020_raw\n",
      "Examining data np_perdigao_high_res_1H_2020_std\n",
      "Loading data np_perdigao_high_res_1H_2020_std from file ../data/preprocessed/np_gan_standard.h5\n",
      "Got data_x with shape:(8520, 96, 96, 2), data_y with shape:(8520, 192, 192, 2)\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"../data/preprocessed/\"\n",
    "file_format = \"np_gan_standard\"\n",
    "xy_keyword_dict = {\"x\":\"low\", \"y\":\"high\"}\n",
    "data_xy = get_data_xy_from_h5(output_folder, file_format, xy_keyword_dict, exclude_list = [\"stddev\", \"mean\",\"raw\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b14520-0c82-4b03-a2a6-c88fe8a86e5f",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36f670-4e9b-49b8-b46a-afc4f3a6d1de",
   "metadata": {},
   "source": [
    "### Key parameters\n",
    "The parameters for HIER-AE are explained below:\n",
    "1. For training, ``` parameters[\"train\"] ```:\n",
    "    - ``` \"batch_size\", \"shuffle\"```: the generic parameters for improvements\n",
    "    - ``` \"n_sub_net\" ```: number of sub nets in the hierarchi\n",
    "    - ``` \"latent_dim_en\" ```: latent dimension size of the encoder \n",
    "    - ``` \"latent_dim_de_origin\" ```: latent dimension size of the decoder in the lowest level, later ones will be multiplied by the number of level.\n",
    "    - ``` \"log_path_file_format\" ```: file_format for string formatting for log output\n",
    "    - ``` \"sub_net_epochs\" ```: number of epochs for each level of sub net\n",
    "2. For data IO and manipulation, ``` parameters[\"data\"] ```:\n",
    "    - ``` \"output_folder\" ```: the output folder of the data preprocess, used as input for loading data\n",
    "    - ``` \"file_format\" ```: the file name format used for standardrized data file h5\n",
    "    - ``` \"xy_keyword_dict\" ```: the data name key used for detecting and catogorizing x and y from h5 standardrized datasets. Here we only load high res data and use y the same as x\n",
    "    - ``` \"xy_exclude_list\" ```: list of dataset type to be skipped if appeared in the data set name, like stddev, mean and std if we only need raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021735a6-557d-46aa-a742-377f9287dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_AE = dict()\n",
    "\n",
    "parameters_AE[\"train\"] = {\"batch_size\": 128,\n",
    "                       \"shuffle\": True,\n",
    "                       \"n_sub_net\":4,\n",
    "                       \"latent_dim_en\":18,\n",
    "                       \"latent_dim_de_origin\":18,\n",
    "                       \"log_path_file_format\":\"../data/log/%s\",\n",
    "                       \"sub_net_epochs\":[5,4,3,2]}\n",
    "parameters_AE[\"data\"] = {'output_folder': \"../data/preprocessed/\",\n",
    "                      'file_format': \"np_gan_standard\",\n",
    "                      'xy_keyword_dict': {\"x\":\"high\", \"y\":\"high\"}, #only load high res data\n",
    "                      'xy_exclude_list': [\"stddev\", \"mean\",\"std\"]} #here we only need to load \"raw\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f9bd8be-d5b5-4a6d-b44e-b1f761cfa253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AWWSM4_HIER_AE with parameters:\n",
      "{'train': {'batch_size': 128, 'shuffle': True, 'n_sub_net': 4, 'latent_dim_en': 18, 'latent_dim_de_origin': 18, 'log_path_file_format': '../data/log/%s', 'sub_net_epochs': [5, 4, 3, 2]}, 'data': {'output_folder': '../data/preprocessed/', 'file_format': 'np_gan_standard', 'xy_keyword_dict': {'x': 'high', 'y': 'high'}, 'xy_exclude_list': ['stddev', 'mean', 'std']}}\n",
      "Data in file ../data/preprocessed/np_gan_standard.h5 are: \n",
      " ['np_perdigao_high_res_1H_2020_mean', 'np_perdigao_high_res_1H_2020_raw', 'np_perdigao_high_res_1H_2020_std', 'np_perdigao_high_res_1H_2020_stddev', 'np_perdigao_low_res_1H_2020_mean', 'np_perdigao_low_res_1H_2020_raw', 'np_perdigao_low_res_1H_2020_std', 'np_perdigao_low_res_1H_2020_stddev']\n",
      "Examining data np_perdigao_high_res_1H_2020_mean\n",
      "Examining data np_perdigao_high_res_1H_2020_raw\n",
      "Loading data np_perdigao_high_res_1H_2020_raw from file ../data/preprocessed/np_gan_standard.h5\n",
      "Data in file ../data/preprocessed/np_gan_standard.h5 are: \n",
      " ['np_perdigao_high_res_1H_2020_mean', 'np_perdigao_high_res_1H_2020_raw', 'np_perdigao_high_res_1H_2020_std', 'np_perdigao_high_res_1H_2020_stddev', 'np_perdigao_low_res_1H_2020_mean', 'np_perdigao_low_res_1H_2020_raw', 'np_perdigao_low_res_1H_2020_std', 'np_perdigao_low_res_1H_2020_stddev']\n",
      "Examining data np_perdigao_high_res_1H_2020_mean\n",
      "Examining data np_perdigao_high_res_1H_2020_raw\n",
      "Loading data np_perdigao_high_res_1H_2020_raw from file ../data/preprocessed/np_gan_standard.h5\n",
      "Got data_x with shape:(8520, 192, 192, 2), data_y with shape:(8520, 192, 192, 2)\n",
      "X_train.shape: (5112, 192, 192, 2)\n",
      "X_val.shape: (1704, 192, 192, 2)\n",
      "X_test.shape: (1704, 192, 192, 2)\n",
      "19.913855 19.156878 19.736868 -16.306587 -15.775822 -16.26034\n",
      "Doing the 1th sub autoencoder.\n",
      "Keeping latent dimension size for encoder same: 18\n",
      "Latent dimension size for decoder of the 1th AE is: 18 = 18 * 1\n",
      "Executing: encoder_18_sub1 = encoder(18)\n",
      "Executing: print(encoder_18_sub1.summary())\n",
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 192, 192, 2)]     0         \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 192, 192, 16)      304       \n",
      "                                                                 \n",
      " batch_normalization_104 (Ba  (None, 192, 192, 16)     64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_165 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 96, 96, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_100 (Conv2D)         (None, 96, 96, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_105 (Ba  (None, 96, 96, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_166 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " max_pooling2d_79 (MaxPoolin  (None, 48, 48, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_101 (Conv2D)         (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_106 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_167 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_102 (Conv2D)         (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_107 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_168 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_103 (Conv2D)         (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_169 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_104 (Conv2D)         (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " leaky_re_lu_170 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 576)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 18)                10386     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,706\n",
      "Trainable params: 82,514\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: decoder_18_sub1 = decoder(18)\n",
      "Executing: print(decoder_18_sub1.summary())\n",
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 18)]              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 576)               10944     \n",
      "                                                                 \n",
      " reshape_13 (Reshape)        (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_114 (Conv2  (None, 6, 6, 64)         36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_108 (Ba  (None, 6, 6, 64)         256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_171 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_115 (Conv2  (None, 12, 12, 64)       36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_109 (Ba  (None, 12, 12, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_172 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_116 (Conv2  (None, 24, 24, 32)       18464     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_110 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_173 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_117 (Conv2  (None, 48, 48, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_111 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_174 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_118 (Conv2  (None, 96, 96, 16)       4624      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_175 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_119 (Conv2  (None, 192, 192, 16)     2320      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_176 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " conv2d_105 (Conv2D)         (None, 192, 192, 2)       290       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,514\n",
      "Trainable params: 120,130\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: autoencoder_18_hier_1 = Autoencoder_hier_1(encoder_18_sub1, decoder_18_sub1)\n",
      "Executing: autoencoder_18_hier_1.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
      "Preparation done! Do the training now!\n",
      "Executing: training_history_hier_1 = autoencoder_18_hier_1.fit(self.X_train, self.X_train,batch_size=128, epochs=5, shuffle=True,validation_data=(self.X_val, self.X_val), callbacks=[tensorboard_callback, model_checkpoint_callback])\n",
      "Epoch 1/5\n",
      "40/40 [==============================] - 4s 79ms/step - loss: 7.4801 - val_loss: 9.0357\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - 3s 66ms/step - loss: 5.0296 - val_loss: 7.8056\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 4.4273 - val_loss: 7.3182\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 3.7660 - val_loss: 4.5233\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - 3s 65ms/step - loss: 1.5073 - val_loss: 2.1646\n",
      "Executing: autoencoder_18_hier_1.evaluate(self.X_test, self.X_test)\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 2.2422\n",
      "The 1th round of AE done! Update the prev HIER to be the current HIER!\n",
      "Doing the 2th sub autoencoder.\n",
      "Keeping latent dimension size for encoder same: 18\n",
      "Latent dimension size for decoder of the 2th AE is: 36 = 18 * 2\n",
      "Executing: encoder_18_sub2 = encoder(18)\n",
      "Executing: print(encoder_18_sub2.summary())\n",
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 192, 192, 2)]     0         \n",
      "                                                                 \n",
      " conv2d_106 (Conv2D)         (None, 192, 192, 16)      304       \n",
      "                                                                 \n",
      " batch_normalization_112 (Ba  (None, 192, 192, 16)     64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_177 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " max_pooling2d_84 (MaxPoolin  (None, 96, 96, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_107 (Conv2D)         (None, 96, 96, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_113 (Ba  (None, 96, 96, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_178 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " max_pooling2d_85 (MaxPoolin  (None, 48, 48, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_108 (Conv2D)         (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_114 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_179 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_86 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_115 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_180 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_181 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " leaky_re_lu_182 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 576)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 18)                10386     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,706\n",
      "Trainable params: 82,514\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: decoder_18_sub2 = decoder(36)\n",
      "Executing: print(decoder_18_sub2.summary())\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 36)]              0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 576)               21312     \n",
      "                                                                 \n",
      " reshape_14 (Reshape)        (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_120 (Conv2  (None, 6, 6, 64)         36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_116 (Ba  (None, 6, 6, 64)         256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_183 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_121 (Conv2  (None, 12, 12, 64)       36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_117 (Ba  (None, 12, 12, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_184 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_122 (Conv2  (None, 24, 24, 32)       18464     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_118 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_185 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_123 (Conv2  (None, 48, 48, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_119 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_186 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_124 (Conv2  (None, 96, 96, 16)       4624      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_187 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_125 (Conv2  (None, 192, 192, 16)     2320      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_188 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 192, 192, 2)       290       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,882\n",
      "Trainable params: 130,498\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: autoencoder_18_hier_2 = Autoencoder_hier_2(encoder_18_sub2, decoder_18_sub2, autoencoder_18_hier_1)\n",
      "Executing: autoencoder_18_hier_2.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
      "Preparation done! Do the training now!\n",
      "Executing: training_history_hier_2 = autoencoder_18_hier_2.fit(self.X_train, self.X_train,batch_size=128, epochs=4, shuffle=True,validation_data=(self.X_val, self.X_val), callbacks=[tensorboard_callback, model_checkpoint_callback])\n",
      "Epoch 1/4\n",
      "40/40 [==============================] - 5s 88ms/step - loss: 6.6723 - val_loss: 7.2464\n",
      "Epoch 2/4\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 4.6378 - val_loss: 6.8240\n",
      "Epoch 3/4\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 3.8046 - val_loss: 4.3377\n",
      "Epoch 4/4\n",
      "40/40 [==============================] - 3s 71ms/step - loss: 1.7949 - val_loss: 2.5333\n",
      "Executing: autoencoder_18_hier_1.evaluate(self.X_test, self.X_test)\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 2.2422\n",
      "Executing: autoencoder_18_hier_2.evaluate(self.X_test, self.X_test)\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 2.5779\n",
      "The 2th round of AE done! Update the prev HIER to be the current HIER!\n",
      "Doing the 3th sub autoencoder.\n",
      "Keeping latent dimension size for encoder same: 18\n",
      "Latent dimension size for decoder of the 3th AE is: 54 = 18 * 3\n",
      "Executing: encoder_18_sub3 = encoder(18)\n",
      "Executing: print(encoder_18_sub3.summary())\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 192, 192, 2)]     0         \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 192, 192, 16)      304       \n",
      "                                                                 \n",
      " batch_normalization_120 (Ba  (None, 192, 192, 16)     64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_189 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " max_pooling2d_90 (MaxPoolin  (None, 96, 96, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 96, 96, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_121 (Ba  (None, 96, 96, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_190 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " max_pooling2d_91 (MaxPoolin  (None, 48, 48, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_122 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_191 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_92 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_123 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_192 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_93 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_193 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_94 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " leaky_re_lu_194 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPoolin  (None, 3, 3, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 576)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 18)                10386     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,706\n",
      "Trainable params: 82,514\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: decoder_18_sub3 = decoder(54)\n",
      "Executing: print(decoder_18_sub3.summary())\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 54)]              0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 576)               31680     \n",
      "                                                                 \n",
      " reshape_15 (Reshape)        (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_126 (Conv2  (None, 6, 6, 64)         36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_124 (Ba  (None, 6, 6, 64)         256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_195 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_127 (Conv2  (None, 12, 12, 64)       36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_125 (Ba  (None, 12, 12, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_196 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_128 (Conv2  (None, 24, 24, 32)       18464     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_126 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_197 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_129 (Conv2  (None, 48, 48, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_127 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_198 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_130 (Conv2  (None, 96, 96, 16)       4624      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_199 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_131 (Conv2  (None, 192, 192, 16)     2320      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_200 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 192, 192, 2)       290       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141,250\n",
      "Trainable params: 140,866\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: autoencoder_18_hier_3 = Autoencoder_hier_3(encoder_18_sub3, decoder_18_sub3, autoencoder_18_hier_2)\n",
      "Executing: autoencoder_18_hier_3.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
      "Preparation done! Do the training now!\n",
      "Executing: training_history_hier_3 = autoencoder_18_hier_3.fit(self.X_train, self.X_train,batch_size=128, epochs=3, shuffle=True,validation_data=(self.X_val, self.X_val), callbacks=[tensorboard_callback, model_checkpoint_callback])\n",
      "Epoch 1/3\n",
      "40/40 [==============================] - 5s 93ms/step - loss: 7.1052 - val_loss: 6.1761\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 4.9879 - val_loss: 5.6597\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 4.0023 - val_loss: 4.7526\n",
      "Executing: autoencoder_18_hier_2.evaluate(self.X_test, self.X_test)\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 2.5779\n",
      "Executing: autoencoder_18_hier_3.evaluate(self.X_test, self.X_test)\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 4.9525\n",
      "The 3th round of AE done! Update the prev HIER to be the current HIER!\n",
      "Doing the 4th sub autoencoder.\n",
      "Keeping latent dimension size for encoder same: 18\n",
      "Latent dimension size for decoder of the 4th AE is: 72 = 18 * 4\n",
      "Executing: encoder_18_sub4 = encoder(18)\n",
      "Executing: print(encoder_18_sub4.summary())\n",
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_35 (InputLayer)       [(None, 192, 192, 2)]     0         \n",
      "                                                                 \n",
      " conv2d_120 (Conv2D)         (None, 192, 192, 16)      304       \n",
      "                                                                 \n",
      " batch_normalization_128 (Ba  (None, 192, 192, 16)     64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_201 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 96, 96, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 96, 96, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_129 (Ba  (None, 96, 96, 16)       64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_202 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 48, 48, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_130 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_203 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_98 (MaxPoolin  (None, 24, 24, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_131 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_204 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_99 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_205 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_100 (MaxPooli  (None, 6, 6, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 6, 6, 64)          36928     \n",
      "                                                                 \n",
      " leaky_re_lu_206 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " max_pooling2d_101 (MaxPooli  (None, 3, 3, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 576)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 18)                10386     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,706\n",
      "Trainable params: 82,514\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: decoder_18_sub4 = decoder(72)\n",
      "Executing: print(decoder_18_sub4.summary())\n",
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 72)]              0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 576)               42048     \n",
      "                                                                 \n",
      " reshape_16 (Reshape)        (None, 3, 3, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_132 (Conv2  (None, 6, 6, 64)         36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_132 (Ba  (None, 6, 6, 64)         256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_207 (LeakyReLU)  (None, 6, 6, 64)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_133 (Conv2  (None, 12, 12, 64)       36928     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_133 (Ba  (None, 12, 12, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_208 (LeakyReLU)  (None, 12, 12, 64)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_134 (Conv2  (None, 24, 24, 32)       18464     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_134 (Ba  (None, 24, 24, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_209 (LeakyReLU)  (None, 24, 24, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_135 (Conv2  (None, 48, 48, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " batch_normalization_135 (Ba  (None, 48, 48, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " leaky_re_lu_210 (LeakyReLU)  (None, 48, 48, 32)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_136 (Conv2  (None, 96, 96, 16)       4624      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_211 (LeakyReLU)  (None, 96, 96, 16)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_137 (Conv2  (None, 192, 192, 16)     2320      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " leaky_re_lu_212 (LeakyReLU)  (None, 192, 192, 16)     0         \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 192, 192, 2)       290       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,618\n",
      "Trainable params: 151,234\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n",
      "Executing: autoencoder_18_hier_4 = Autoencoder_hier_4(encoder_18_sub4, decoder_18_sub4, autoencoder_18_hier_3)\n",
      "Executing: autoencoder_18_hier_4.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
      "Preparation done! Do the training now!\n",
      "Executing: training_history_hier_4 = autoencoder_18_hier_4.fit(self.X_train, self.X_train,batch_size=128, epochs=2, shuffle=True,validation_data=(self.X_val, self.X_val), callbacks=[tensorboard_callback, model_checkpoint_callback])\n",
      "Epoch 1/2\n",
      "40/40 [==============================] - 5s 99ms/step - loss: 7.7630 - val_loss: 6.6062\n",
      "Epoch 2/2\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 4.8854 - val_loss: 5.6286\n",
      "Executing: autoencoder_18_hier_3.evaluate(self.X_test, self.X_test)\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 4.9525\n",
      "Executing: autoencoder_18_hier_4.evaluate(self.X_test, self.X_test)\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 5.9533\n",
      "The 4th round of AE done! Update the prev HIER to be the current HIER!\n"
     ]
    }
   ],
   "source": [
    "### Step by step running example\n",
    "#initialize model with parameters_AE\n",
    "model_AE = AWWSM4_HIER_AE(parameters_AE)\n",
    "#load data\n",
    "model_AE.load_data()\n",
    "#split data\n",
    "model_AE.split_data()\n",
    "#perform the training for each sub net one by one\n",
    "model_AE.generate_AE_one_by_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fad0a1-d45e-4ed6-a79e-90d11c9e55d2",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f9960-a475-4c09-b9e2-323f4fad76d9",
   "metadata": {},
   "source": [
    "### Key parameters\n",
    "The parameters for GAN are explained below:\n",
    "1. For training, ``` parameters[\"train\"] ```:\n",
    "    - ``` \"learning_rate_g\" ```: the learning rate for the generator\n",
    "    - ``` \"learning_rate_d\" ```: the learning rate for the discriminator\n",
    "    - ``` \"beta_1\", \"beta_2\", \"epsilon\", \"batch_size\"```: the generic parameters for improvements\n",
    "    - ``` \"n_epochs_pretrain\" ```: number of epochs for pretraining\n",
    "    - ``` \"n_epochs_GAN\" ```: number of epochs for full GAN\n",
    "2. For data IO and manipulation, ``` parameters[\"data\"] ```:\n",
    "    - ``` \"output_folder\" ```: the output folder of the data preprocess, used as input for loading data\n",
    "    - ``` \"file_format\" ```: the file name format used for standardrized data file h5\n",
    "    - ``` \"xy_keyword_dict\" ```: the data name key used for detecting and catogorizing x and y from h5 standardrized datasets \n",
    "    - ``` \"xy_exclude_list\" ```: list of dataset type to be skipped if appeared in the data set name, like stddev, mean, raw if we only need standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c9fdddc-2981-4b55-991b-37b72e2cb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_GAN = dict()\n",
    "\n",
    "parameters_GAN[\"train\"] = {\"learning_rate_g\": 1e-4, \n",
    "                       \"learning_rate_d\": 1e-4,\n",
    "                       \"beta_1\": 0.9,\n",
    "                       \"beta_2\": 0.999,\n",
    "                       \"epsilon\": 1e-08,\n",
    "                       \"batch_size\": 128,\n",
    "                       \"alpha_advers\": 1e-3,\n",
    "                       \"n_epochs_pretrain\":1, \n",
    "                       \"n_epochs_GAN\":1}\n",
    "parameters_GAN[\"data\"] = {'output_folder': \"../data/preprocessed/\",\n",
    "                      'file_format': \"np_gan_standard\",\n",
    "                      'xy_keyword_dict': {\"x\":\"low\", \"y\":\"high\"},\n",
    "                      'xy_exclude_list': [\"stddev\", \"mean\",\"raw\"]} #only keep the \"std\"(standardrized) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50afcf80-b144-4a2d-b829-701f3579200a",
   "metadata": {},
   "source": [
    "### Step by step running example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a66421eb-eb8d-4592-bc71-861be12a226d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 96, 96, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 96, 96, 64)  1216        ['input_1[0][0]']                \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 96, 96, 64)   0           ['conv2d_transpose[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation[0][0]']             \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_1[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 96, 96, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 96, 96, 64)  36928       ['add[0][0]']                    \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_2[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_4[0][0]',     \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 96, 96, 64)  36928       ['add_1[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_3[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_6[0][0]',     \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 96, 96, 64)  36928       ['add_2[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 96, 96, 64)  36928       ['activation_4[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_8[0][0]',     \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 96, 96, 64)  36928       ['add_3[0][0]']                  \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_5[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_10[0][0]',    \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_4[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_6[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_12[0][0]',    \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_13 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_5[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_13[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_14 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_7[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_14[0][0]',    \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_15 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_6[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_15[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_16 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_8[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_16[0][0]',    \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_17 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_7[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 96, 96, 64)   0           ['conv2d_transpose_17[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_18 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_9[0][0]']           \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_18[0][0]',    \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_19 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_8[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_19[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_20 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_10[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 96, 96, 64)   0           ['conv2d_transpose_20[0][0]',    \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_21 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_9[0][0]']                  \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_21[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_22 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_11[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_22[0][0]',    \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_transpose_23 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_10[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_23[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_24 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_12[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_24[0][0]',    \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_25 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_11[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_25[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_26 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_13[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_26[0][0]',    \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_27 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_12[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_27[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_28 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_14[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_28[0][0]',    \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_29 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_13[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_29[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_30 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_15[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_30[0][0]',    \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_31 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_14[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 96, 96, 64)   0           ['conv2d_transpose_31[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_32 (Conv2DTra  (None, 96, 96, 64)  36928       ['activation_16[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_32[0][0]',    \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_33 (Conv2DTra  (None, 96, 96, 64)  36928       ['add_15[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 96, 96, 64)   0           ['conv2d_transpose_33[0][0]',    \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_34 (Conv2DTra  (None, 96, 96, 256)  147712     ['add_16[0][0]']                 \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 192, 192, 64  0           ['conv2d_transpose_34[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 192, 192, 64  0           ['lambda[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_35 (Conv2DTra  (None, 192, 192, 2)  1154       ['activation_17[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,368,706\n",
      "Trainable params: 1,368,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 192, 192, 2)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 192, 192, 32)      608       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 192, 192, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 96, 96, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 48, 48, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 48, 48, 128)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 24, 24, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              37749760  \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,922,753\n",
      "Trainable params: 38,922,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Data in file ../data/preprocessed/np_gan_standard.h5 are: \n",
      " ['np_perdigao_high_res_1H_2020_mean', 'np_perdigao_high_res_1H_2020_raw', 'np_perdigao_high_res_1H_2020_std', 'np_perdigao_high_res_1H_2020_stddev', 'np_perdigao_low_res_1H_2020_mean', 'np_perdigao_low_res_1H_2020_raw', 'np_perdigao_low_res_1H_2020_std', 'np_perdigao_low_res_1H_2020_stddev']\n",
      "Examining data np_perdigao_high_res_1H_2020_mean\n",
      "Examining data np_perdigao_high_res_1H_2020_raw\n",
      "Examining data np_perdigao_high_res_1H_2020_std\n",
      "Examining data np_perdigao_high_res_1H_2020_stddev\n",
      "Examining data np_perdigao_low_res_1H_2020_mean\n",
      "Examining data np_perdigao_low_res_1H_2020_raw\n",
      "Examining data np_perdigao_low_res_1H_2020_std\n",
      "Loading data np_perdigao_low_res_1H_2020_std from file ../data/preprocessed/np_gan_standard.h5\n",
      "Data in file ../data/preprocessed/np_gan_standard.h5 are: \n",
      " ['np_perdigao_high_res_1H_2020_mean', 'np_perdigao_high_res_1H_2020_raw', 'np_perdigao_high_res_1H_2020_std', 'np_perdigao_high_res_1H_2020_stddev', 'np_perdigao_low_res_1H_2020_mean', 'np_perdigao_low_res_1H_2020_raw', 'np_perdigao_low_res_1H_2020_std', 'np_perdigao_low_res_1H_2020_stddev']\n",
      "Examining data np_perdigao_high_res_1H_2020_mean\n",
      "Examining data np_perdigao_high_res_1H_2020_raw\n",
      "Examining data np_perdigao_high_res_1H_2020_std\n",
      "Loading data np_perdigao_high_res_1H_2020_std from file ../data/preprocessed/np_gan_standard.h5\n",
      "Got data_x with shape:(8520, 96, 96, 2), data_y with shape:(8520, 192, 192, 2)\n",
      "x_train.shape: (5112, 96, 96, 2)\n",
      "x_val.shape: (1704, 96, 96, 2)\n",
      "x_test.shape: (1704, 96, 96, 2)\n",
      "y_train.shape: (5112, 192, 192, 2)\n",
      "y_val.shape: (1704, 192, 192, 2)\n",
      "y_test.shape: (1704, 192, 192, 2)\n",
      "6.890482 5.989441 5.7024393 -5.4777956 -5.0524907 -5.5057893\n",
      "7.035497 5.8600492 6.0442076 -5.315754 -5.2317853 -5.2996855\n",
      "Training network ...\n",
      "Epoch: 1\n",
      "Epoch generator training loss = 0.421310, val loss = 0.097912\n",
      "Epoch took 22.87 seconds\n",
      "\n",
      "Epoch: 2\n",
      "Epoch generator training loss = 0.078023, val loss = 0.065026\n",
      "Epoch took 18.54 seconds\n",
      "\n",
      "Epoch: 3\n",
      "Epoch generator training loss = 0.057257, val loss = 0.051252\n",
      "Epoch took 18.54 seconds\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39msplit_data()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# pretrain and save the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#use default epoch value = 20\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msave_gen_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./temp_v0_gen.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# OPTIONAL: create another model which loaded the pretrained weights and can continue doing pretrain\u001b[39;00m\n",
      "File \u001b[0;32m/global/cfs/cdirs/mp7/biwang/TEST_2021/SMC_data_2022/code/data-challenge-2022/./lib/GAN_class.py:217\u001b[0m, in \u001b[0;36mAWWSM4_SR_GAN.pretrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gen_tape:\n\u001b[1;32m    216\u001b[0m \tbatch_SR \u001b[38;5;241m=\u001b[39m gen_model(batch_LR, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 217\u001b[0m \tgen_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gen_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_HR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_SR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m grad_of_gen \u001b[38;5;241m=\u001b[39m gen_tape\u001b[38;5;241m.\u001b[39mgradient(gen_loss, gen_model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m    220\u001b[0m adam\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grad_of_gen, gen_model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[0;32m/global/cfs/cdirs/mp7/biwang/TEST_2021/SMC_data_2022/code/data-challenge-2022/./lib/GAN_class.py:172\u001b[0m, in \u001b[0;36mAWWSM4_SR_GAN.compute_gen_loss\u001b[0;34m(self, x_HR, x_SR, d_SR)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_gen_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_HR, x_SR, d_SR):\n\u001b[0;32m--> 172\u001b[0m \tcontent_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean((\u001b[43mx_HR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_SR\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    173\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_GAN \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoing_pretrain \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m: \u001b[38;5;66;03m#generator, High-Res and Super-Res, Distriminator Super-Res\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \t\t\u001b[38;5;66;03m#content loss + advers loss, return tot_loss, content_loss, adver_loss\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \t\talpha_advers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha_advers\u001b[39m\u001b[38;5;124m'\u001b[39m]\t\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1406\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1402\u001b[0m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[1;32m   1403\u001b[0m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m   1404\u001b[0m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[1;32m   1405\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y)\n\u001b[0;32m-> 1406\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1408\u001b[0m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1412\u001b[0m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_name):\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:548\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmath.subtract\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtract\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39mregister_binary_elementwise_api\n\u001b[1;32m    546\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubtract\u001b[39m(x, y, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 548\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q2/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:11162\u001b[0m, in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  11160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m  11161\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m> 11162\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11163\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSub\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m  11165\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create a GAN model class with doing_pretrain = True \n",
    "model = AWWSM4_SR_GAN(parameters=parameters_GAN, is_GAN=True, doing_pretrain=True) \n",
    "# load and split data based on the parameters[\"data\"]\n",
    "model.load_data()\n",
    "model.split_data()\n",
    "# pretrain and save the model\n",
    "model.pretrain() #use default epoch value = 20\n",
    "model.save_gen_model(\"./temp_v0_gen.h5\")\n",
    "# OPTIONAL: create another model which loaded the pretrained weights and can continue doing pretrain\n",
    "model2 = AWWSM4_SR_GAN(parameters=parameters_GAN, is_GAN=True, doing_pretrain=True)\n",
    "model2.load_gen_model(\"./temp_v0_gen.h5\")\n",
    "model2.load_data()\n",
    "model2.split_data()\n",
    "# continue to work on GAN\n",
    "model.reset_working_mode(doing_pretrain=False)\n",
    "model.train_GAN(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cbba9dd-a989-4be0-9a75-4c08191f380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset the working mode!\n",
      "Working mode before reset:\n",
      "Current working mode is:\n",
      "\t auto_run: False\n",
      "\t is_GAN: True\n",
      "\t doing_pretrain: True\n",
      "\t loading_pretrain: False\n",
      "Working mode after reset:\n",
      "Current working mode is:\n",
      "\t auto_run: False\n",
      "\t is_GAN: True\n",
      "\t doing_pretrain: False\n",
      "\t loading_pretrain: True\n",
      "Training network ...\n",
      "Epoch: 1\n",
      "Using d_loss_ideal_range:[0.45, 0.65], g_reflect_max: 20, d_reflect_max: 20\n",
      "Using d_loss_ideal_range:[0.45, 0.65], g_reflect_max: 20, d_reflect_max: 20\n",
      "Using d_loss_ideal_range:[0.45, 0.65], g_reflect_max: 20, d_reflect_max: 20\n",
      "Epoch generator loss = 0.023027, discriminator loss = 0.519160, g_count = 268, d_count = 58\n",
      "Epoch val: g_loss = 0.021964, d_loss = 0.442368, content_loss = 0.021083, advers_loss = 0.880422\n",
      "Epoch took 471.49 seconds\n",
      "\n",
      "Epoch: 2\n",
      "Epoch generator loss = 0.020886, discriminator loss = 0.431552, g_count = 625, d_count = 40\n",
      "Epoch val: g_loss = 0.020655, d_loss = 0.390905, content_loss = 0.019417, advers_loss = 1.238017\n",
      "Epoch took 217.97 seconds\n",
      "\n",
      "Epoch: 3\n",
      "Epoch generator loss = 0.019746, discriminator loss = 0.380574, g_count = 800, d_count = 40\n",
      "Epoch val: g_loss = 0.020212, d_loss = 0.345109, content_loss = 0.018272, advers_loss = 1.939688\n",
      "Epoch took 275.60 seconds\n",
      "\n",
      "Epoch: 4\n",
      "Epoch generator loss = 0.019115, discriminator loss = 0.361841, g_count = 781, d_count = 40\n",
      "Epoch val: g_loss = 0.020073, d_loss = 0.348061, content_loss = 0.017898, advers_loss = 2.175165\n",
      "Epoch took 269.65 seconds\n",
      "\n",
      "Epoch: 5\n",
      "Epoch generator loss = 0.018772, discriminator loss = 0.366936, g_count = 781, d_count = 40\n",
      "Epoch val: g_loss = 0.019578, d_loss = 0.324184, content_loss = 0.017552, advers_loss = 2.026251\n",
      "Epoch took 269.69 seconds\n",
      "\n",
      "Epoch: 6\n",
      "Epoch generator loss = 0.018361, discriminator loss = 0.356463, g_count = 800, d_count = 40\n",
      "Epoch val: g_loss = 0.018679, d_loss = 0.303565, content_loss = 0.017202, advers_loss = 1.477135\n",
      "Epoch took 275.99 seconds\n",
      "\n",
      "Epoch: 7\n",
      "Epoch generator loss = 0.018121, discriminator loss = 0.357041, g_count = 800, d_count = 40\n",
      "Epoch val: g_loss = 0.019180, d_loss = 0.316502, content_loss = 0.016855, advers_loss = 2.324737\n",
      "Epoch took 275.73 seconds\n",
      "\n",
      "Epoch: 8\n",
      "Epoch generator loss = 0.021540, discriminator loss = 0.357314, g_count = 800, d_count = 40\n",
      "Epoch val: g_loss = 0.030749, d_loss = 0.200105, content_loss = 0.028279, advers_loss = 2.470253\n",
      "Epoch took 275.64 seconds\n",
      "\n",
      "Epoch: 9\n",
      "Epoch generator loss = 0.020857, discriminator loss = 0.139703, g_count = 800, d_count = 40\n",
      "Epoch val: g_loss = 0.020222, d_loss = 0.180832, content_loss = 0.017926, advers_loss = 2.296219\n",
      "Epoch took 275.72 seconds\n",
      "\n",
      "Epoch: 10\n",
      "Epoch generator loss = 0.018929, discriminator loss = 0.331573, g_count = 800, d_count = 40\n",
      "Epoch val: g_loss = 0.019397, d_loss = 0.344015, content_loss = 0.017393, advers_loss = 2.003562\n",
      "Epoch took 275.85 seconds\n",
      "\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.engine.functional.Functional at 0x7fc6dc5a1910>,\n",
       " <keras.engine.functional.Functional at 0x7fc6dc55c220>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_working_mode(doing_pretrain=False)\n",
    "model.train_GAN(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f02abf-1cca-4114-add3-aedc16cbd826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
