# data-challenge-2022

First step is to do data preprocessing. This can be found in data-preprocess-ae.ipynb and data-preprocess-gan.ipynb

Second step is to train/load the model. For autoencoder, model are saved in either autoencoder_<num>, where <num> is the number of dimension of latent space, or autoencoder_18_hier_<num>, where <num> here represent the number of subnetwork in a hierarchcal architechture
